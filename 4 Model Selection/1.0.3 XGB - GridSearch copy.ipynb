{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "import xgboost as xgb\n",
        "import time\n",
        "import itertools\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   425_pct_Al  M_Value  C4_pct_Eth  C4_pct_H2O  C4_pct_Hex  \\\n",
            "0    6.307630  3.50893    2.508420    21.96340    0.659256   \n",
            "1    6.308335  3.50863    2.511135    21.96865    0.659930   \n",
            "2    6.309390  3.50818    2.515210    21.97655    0.660942   \n",
            "3    6.310090  3.50788    2.517925    21.98185    0.661616   \n",
            "4    6.310790  3.50758    2.520640    21.98715    0.662291   \n",
            "\n",
            "   HydWtr_pct_Ammonia  HydWtr_Na2O   DI55152   FC55003       FC55552  \\\n",
            "0            0.908765     2.712180  0.925255  4919.290  41564.100000   \n",
            "1            0.907643     2.805415  0.924281  5039.445  41558.250000   \n",
            "2            0.905959     2.945270  0.923773  5268.620  41524.066667   \n",
            "3            0.904837     3.038505  0.924103  5349.320  41500.275000   \n",
            "4            0.903715     3.131740  0.924258  5563.165  41466.625000   \n",
            "\n",
            "       FC55569  FFC55553  FFC55555    LC55555   PI55004   TC55552     TC55555  \\\n",
            "0  6918.110000  0.996975  0.751501  59.968800  1.306310  177.1880  180.125000   \n",
            "1  6919.960000  0.998847  0.750588  59.932300  1.181220  177.2505  180.053000   \n",
            "2  6916.486667  0.998648  0.750505  60.002433  1.216603  177.4170  180.001667   \n",
            "3  6918.470000  1.000349  0.750325  60.015925  1.206718  177.4590  180.010750   \n",
            "4  6915.790000  1.000862  0.750021  60.020500  1.163892  177.5490  179.939500   \n",
            "\n",
            "      TI55021    Butanol  \n",
            "0  212.861000  54.858300  \n",
            "1  212.699000  51.190050  \n",
            "2  212.822333  48.744567  \n",
            "3  212.799750  46.604750  \n",
            "4  212.853000  44.587220  \n"
          ]
        }
      ],
      "source": [
        "# df_TagDesc = pd.read_csv(r'C:\\Users\\saust\\OneDrive\\Desktop\\GitRepo\\Project-OptiC4\\CSV\\Not for Processing\\TagDesc.csv')\n",
        "\n",
        "df_All_1 = pd.read_csv(r'C:\\Users\\saust\\OneDrive\\Desktop\\GitRepo\\Project-OptiC4\\1 Preprocess\\Merge Data\\contData_all_Avg_1o2.csv')\n",
        "df_All_2 = pd.read_csv(r'C:\\Users\\saust\\OneDrive\\Desktop\\GitRepo\\Project-OptiC4\\1 Preprocess\\Merge Data\\contData_all_Avg_2o2.csv')\n",
        "# Concatenate (union) the dataframes\n",
        "df_All = pd.concat([df_All_1, df_All_2], ignore_index=True)\n",
        "\n",
        "print(df_All.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Set max columns to display\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of columns to exclude to run XGboost feature selection\n",
        "exclude_columns = [#'Date',\n",
        "                 'C4_pct_Hex', 'HydWtr_Na2O',\n",
        "                 'TC55555'  \n",
        "                   ]\n",
        "\n",
        "# Create a new DataFrame without the excluded columnsd\n",
        "df_All = df_All.drop(columns=exclude_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         425_pct_Al       M_Value    C4_pct_Eth    C4_pct_H2O  \\\n",
            "count  54701.000000  54701.000000  54701.000000  54701.000000   \n",
            "mean       6.112584      3.604726      1.274754     20.756146   \n",
            "std        0.316017      0.173736      0.677477      2.859486   \n",
            "min        0.252306      1.461875      0.086948      7.932310   \n",
            "25%        5.987750      3.506780      0.675285     18.331550   \n",
            "50%        6.130470      3.595655      1.291115     20.731850   \n",
            "75%        6.270075      3.696090      1.719630     22.989150   \n",
            "max        8.020685      5.827565      8.711360     33.731050   \n",
            "\n",
            "       HydWtr_pct_Ammonia       DI55152       FC55003       FC55552  \\\n",
            "count        54701.000000  54701.000000  54701.000000  54701.000000   \n",
            "mean             0.969410      0.944165   5946.323971  36128.859598   \n",
            "std              0.144668      0.042737    794.065219   4270.390546   \n",
            "min              0.390025      0.815428   2991.532500  18800.350000   \n",
            "25%              0.877716      0.915431   5446.200000  34993.125000   \n",
            "50%              0.942521      0.939170   5961.932500  37885.750000   \n",
            "75%              1.036325      0.965307   6492.420000  38978.150000   \n",
            "max              1.600715      1.064850   8892.395000  42079.525000   \n",
            "\n",
            "            FC55569      FFC55553      FFC55555       LC55555       PI55004  \\\n",
            "count  54701.000000  54701.000000  54701.000000  54701.000000  54701.000000   \n",
            "mean    6598.163591      0.993519      0.774488     58.558857      2.277310   \n",
            "std      372.743929      0.040033      0.023074     10.526737      1.203949   \n",
            "min     5190.967500      0.814484      0.697983     39.179775      0.031410   \n",
            "25%     6363.310000      0.970038      0.759833     49.916475      1.319045   \n",
            "50%     6580.852500      0.991442      0.779014     60.084475      2.031255   \n",
            "75%     6809.940000      1.012430      0.789958     67.886450      3.064095   \n",
            "max     8047.065000      1.159912      0.854999     79.265400      6.313537   \n",
            "\n",
            "            TC55552       TI55021       Butanol  \n",
            "count  54701.000000  54701.000000  54701.000000  \n",
            "mean     168.496587    223.245544      9.491176  \n",
            "std       14.922549      8.910920      9.378743  \n",
            "min      120.497500    207.956750      0.424417  \n",
            "25%      156.057250    217.915500      3.633750  \n",
            "50%      171.831000    220.879250      5.765416  \n",
            "75%      180.383500    224.748000     11.246987  \n",
            "max      212.425000    256.574750     56.575000  \n"
          ]
        }
      ],
      "source": [
        "print(df_All.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Splitting into train and test\n",
        "X = df_All.drop('Butanol', axis=1)  # Assuming 'target' is your target column\n",
        "y = df_All['Butanol']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# scaler = StandardScaler()\n",
        "# X_train = scaler.fit_transform(X_train)\n",
        "# X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define the parameter grid\n",
        "\n",
        "param_grid = {\n",
        "    'learning_rate': [0.05],  # Introduced some intermediate and higher values. 0.05, 0.06, 0.07, 0.08\n",
        "    'n_estimators': [800],     # Expanded around 500, as it was your best result.\n",
        "    'max_depth': [10],                # Introduced values around 7, which was your best depth. 6, 7, 8, \n",
        "    'subsample': [0.6],        # Expanded a bit to include values around 0.8. 0.8, 0.9, 1.0, 0.7, 0.6, 0.5, 0.4\n",
        "    'colsample_bytree': [1],      # Values around your best result of 0.7.  0.6, 0.7, 0.8, 0.9, 1\n",
        "    'gamma': [0],                   # Regularization parameter. Start with these values. 0, 0.1, 0.5 \n",
        "    'alpha': [1.5],                   # L1 regularization term. 0, 0.1, 0.5, 0.7, 0.9, 1, 1.3, 1.4 1.5, 1.6, 2\n",
        "    'lambda': [1.5],                    # L2 regularization term.  1, 1.5, 2\n",
        "    'colsample_bylevel': [0.8],     # Additional column sampling.  0.6, 0.7,0.8 \n",
        "    'colsample_bynode': [0.7]       # More granular column sampling  .0.6, 0.8\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 1, 'colsample_bylevel': 0.6, 'colsample_bynode': 0.6} took 30.96 seconds\n",
            "MSE: 4.9128, MAE: 1.1147, R^2: 0.9435, Adjusted R^2: 0.9435, RMSE: 2.2165\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 1, 'colsample_bylevel': 0.6, 'colsample_bynode': 0.7} took 37.21 seconds\n",
            "MSE: 4.9213, MAE: 1.1115, R^2: 0.9434, Adjusted R^2: 0.9434, RMSE: 2.2184\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 1, 'colsample_bylevel': 0.6, 'colsample_bynode': 0.8} took 35.34 seconds\n",
            "MSE: 4.8325, MAE: 1.0939, R^2: 0.9444, Adjusted R^2: 0.9444, RMSE: 2.1983\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 1, 'colsample_bylevel': 0.7, 'colsample_bynode': 0.6} took 40.09 seconds\n",
            "MSE: 4.9726, MAE: 1.1155, R^2: 0.9428, Adjusted R^2: 0.9428, RMSE: 2.2299\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 1, 'colsample_bylevel': 0.7, 'colsample_bynode': 0.7} took 40.37 seconds\n",
            "MSE: 4.8053, MAE: 1.0929, R^2: 0.9447, Adjusted R^2: 0.9447, RMSE: 2.1921\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 1, 'colsample_bylevel': 0.7, 'colsample_bynode': 0.8} took 40.51 seconds\n",
            "MSE: 4.8356, MAE: 1.0897, R^2: 0.9444, Adjusted R^2: 0.9443, RMSE: 2.1990\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 1, 'colsample_bylevel': 0.8, 'colsample_bynode': 0.6} took 38.26 seconds\n",
            "MSE: 4.8204, MAE: 1.0967, R^2: 0.9445, Adjusted R^2: 0.9445, RMSE: 2.1955\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 1, 'colsample_bylevel': 0.8, 'colsample_bynode': 0.7} took 39.67 seconds\n",
            "MSE: 4.8120, MAE: 1.0875, R^2: 0.9446, Adjusted R^2: 0.9446, RMSE: 2.1936\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 1, 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8} took 40.37 seconds\n",
            "MSE: 4.8218, MAE: 1.0919, R^2: 0.9445, Adjusted R^2: 0.9445, RMSE: 2.1958\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 1.5, 'colsample_bylevel': 0.6, 'colsample_bynode': 0.6} took 34.93 seconds\n",
            "MSE: 4.9368, MAE: 1.1160, R^2: 0.9432, Adjusted R^2: 0.9432, RMSE: 2.2219\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 1.5, 'colsample_bylevel': 0.6, 'colsample_bynode': 0.7} took 35.19 seconds\n",
            "MSE: 4.9131, MAE: 1.1089, R^2: 0.9435, Adjusted R^2: 0.9435, RMSE: 2.2165\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 1.5, 'colsample_bylevel': 0.6, 'colsample_bynode': 0.8} took 36.87 seconds\n",
            "MSE: 4.8139, MAE: 1.0920, R^2: 0.9446, Adjusted R^2: 0.9446, RMSE: 2.1941\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 1.5, 'colsample_bylevel': 0.7, 'colsample_bynode': 0.6} took 34.75 seconds\n",
            "MSE: 4.9273, MAE: 1.1116, R^2: 0.9433, Adjusted R^2: 0.9433, RMSE: 2.2198\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 1.5, 'colsample_bylevel': 0.7, 'colsample_bynode': 0.7} took 36.62 seconds\n",
            "MSE: 4.9039, MAE: 1.0980, R^2: 0.9436, Adjusted R^2: 0.9436, RMSE: 2.2145\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 1.5, 'colsample_bylevel': 0.7, 'colsample_bynode': 0.8} took 38.02 seconds\n",
            "MSE: 4.8364, MAE: 1.0933, R^2: 0.9444, Adjusted R^2: 0.9443, RMSE: 2.1992\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 1.5, 'colsample_bylevel': 0.8, 'colsample_bynode': 0.6} took 38.13 seconds\n",
            "MSE: 4.7898, MAE: 1.0897, R^2: 0.9449, Adjusted R^2: 0.9449, RMSE: 2.1886\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 1.5, 'colsample_bylevel': 0.8, 'colsample_bynode': 0.7} took 37.76 seconds\n",
            "MSE: 4.7627, MAE: 1.0881, R^2: 0.9452, Adjusted R^2: 0.9452, RMSE: 2.1824\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 1.5, 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8} took 40.44 seconds\n",
            "MSE: 4.8328, MAE: 1.0902, R^2: 0.9444, Adjusted R^2: 0.9444, RMSE: 2.1984\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 2, 'colsample_bylevel': 0.6, 'colsample_bynode': 0.6} took 32.87 seconds\n",
            "MSE: 4.9729, MAE: 1.1231, R^2: 0.9428, Adjusted R^2: 0.9428, RMSE: 2.2300\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 2, 'colsample_bylevel': 0.6, 'colsample_bynode': 0.7} took 36.14 seconds\n",
            "MSE: 4.9499, MAE: 1.1126, R^2: 0.9430, Adjusted R^2: 0.9430, RMSE: 2.2248\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 2, 'colsample_bylevel': 0.6, 'colsample_bynode': 0.8} took 38.30 seconds\n",
            "MSE: 4.8676, MAE: 1.1045, R^2: 0.9440, Adjusted R^2: 0.9440, RMSE: 2.2063\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 2, 'colsample_bylevel': 0.7, 'colsample_bynode': 0.6} took 40.81 seconds\n",
            "MSE: 4.9211, MAE: 1.1156, R^2: 0.9434, Adjusted R^2: 0.9434, RMSE: 2.2184\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 2, 'colsample_bylevel': 0.7, 'colsample_bynode': 0.7} took 42.22 seconds\n",
            "MSE: 4.8147, MAE: 1.0955, R^2: 0.9446, Adjusted R^2: 0.9446, RMSE: 2.1943\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 2, 'colsample_bylevel': 0.7, 'colsample_bynode': 0.8} took 40.27 seconds\n",
            "MSE: 4.8115, MAE: 1.0890, R^2: 0.9446, Adjusted R^2: 0.9446, RMSE: 2.1935\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 2, 'colsample_bylevel': 0.8, 'colsample_bynode': 0.6} took 40.46 seconds\n",
            "MSE: 4.8567, MAE: 1.1041, R^2: 0.9441, Adjusted R^2: 0.9441, RMSE: 2.2038\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 2, 'colsample_bylevel': 0.8, 'colsample_bynode': 0.7} took 42.94 seconds\n",
            "MSE: 4.8965, MAE: 1.1001, R^2: 0.9437, Adjusted R^2: 0.9436, RMSE: 2.2128\n",
            "Evaluating {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 2, 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8} took 43.10 seconds\n",
            "MSE: 4.8167, MAE: 1.0876, R^2: 0.9446, Adjusted R^2: 0.9446, RMSE: 2.1947\n",
            "Best Parameters: {'learning_rate': 0.05, 'n_estimators': 800, 'max_depth': 10, 'subsample': 0.6, 'colsample_bytree': 1, 'gamma': 0, 'alpha': 1.5, 'lambda': 1.5, 'colsample_bylevel': 0.8, 'colsample_bynode': 0.7}\n"
          ]
        }
      ],
      "source": [
        "# param_grid = {\n",
        "#     'learning_rate': [0.01, 0.1],\n",
        "#     'n_estimators': [100, 500],\n",
        "#     'max_depth': [3, 5, 7],\n",
        "#     'subsample': [0.8, 1.0],\n",
        "#     'colsample_bytree': [0.3, 0.5, 0.7]\n",
        "# }\n",
        "# Best Parameters: {'learning_rate': 0.1, 'n_estimators': 500, 'max_depth': 7, 'subsample': 0.8, 'colsample_bytree': 0.7}\n",
        "\n",
        "xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', use_label_encoder=False)\n",
        "\n",
        "def product_dict(**kwargs):\n",
        "    keys = kwargs.keys()\n",
        "    vals = kwargs.values()\n",
        "    for instance in itertools.product(*vals):\n",
        "        yield dict(zip(keys, instance))\n",
        "\n",
        "best_score = float('inf')\n",
        "best_params = None\n",
        "results = []\n",
        "\n",
        "# Loop over all combinations of hyperparameters\n",
        "for params in product_dict(**param_grid):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    xgb_reg.set_params(**params)\n",
        "    y_pred = cross_val_predict(xgb_reg, X_train, y_train, cv=3)\n",
        "\n",
        "    mse = mean_squared_error(y_train, y_pred)\n",
        "    mae = mean_absolute_error(y_train, y_pred)\n",
        "    r2 = r2_score(y_train, y_pred)\n",
        "    adj_r2 = 1 - (1-r2)*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    end_time = time.time()\n",
        "    duration = end_time - start_time\n",
        "\n",
        "    print(f\"Evaluating {params} took {duration:.2f} seconds\")\n",
        "    print(f\"MSE: {mse:.4f}, MAE: {mae:.4f}, R^2: {r2:.4f}, Adjusted R^2: {adj_r2:.4f}, RMSE: {rmse:.4f}\")\n",
        "\n",
        "    results.append({\n",
        "        'Parameters': params,\n",
        "        'MSE': mse,\n",
        "        'MAE': mae,\n",
        "        'R^2': r2,\n",
        "        'Adjusted R^2': adj_r2,\n",
        "        'RMSE': rmse,\n",
        "        'Duration': duration\n",
        "    })\n",
        "\n",
        "    if mse < best_score:\n",
        "        best_score = mse\n",
        "        best_params = params\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                          Parameters       MSE       MAE  \\\n",
            "0  {'learning_rate': 0.05, 'n_estimators': 800, '...  4.912828  1.114663   \n",
            "1  {'learning_rate': 0.05, 'n_estimators': 800, '...  4.921252  1.111488   \n",
            "2  {'learning_rate': 0.05, 'n_estimators': 800, '...  4.832467  1.093934   \n",
            "3  {'learning_rate': 0.05, 'n_estimators': 800, '...  4.972566  1.115476   \n",
            "4  {'learning_rate': 0.05, 'n_estimators': 800, '...  4.805282  1.092910   \n",
            "\n",
            "        R^2  Adjusted R^2      RMSE   Duration  \n",
            "0  0.943473      0.943454  2.216490  30.959794  \n",
            "1  0.943376      0.943357  2.218389  37.214747  \n",
            "2  0.944398      0.944379  2.198287  35.337413  \n",
            "3  0.942786      0.942766  2.229925  40.090993  \n",
            "4  0.944711      0.944692  2.192095  40.372811  \n"
          ]
        }
      ],
      "source": [
        "print(results_df.head())\n",
        "\n",
        "# Save DataFrame to CSV file in the same directory as the Jupyter Notebook\n",
        "results_df.to_csv('results.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
