{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install statsmodels\n",
        "# %pip install mlxtend\n",
        "# %pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.formula.api import ols\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import random\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   425_pct_Al  M_Value  C4_pct_Eth  C4_pct_H2O  C4_pct_Hex  \\\n",
            "0    6.307630  3.50893    2.508420    21.96340    0.659256   \n",
            "1    6.308335  3.50863    2.511135    21.96865    0.659930   \n",
            "2    6.309390  3.50818    2.515210    21.97655    0.660942   \n",
            "3    6.310090  3.50788    2.517925    21.98185    0.661616   \n",
            "4    6.310790  3.50758    2.520640    21.98715    0.662291   \n",
            "\n",
            "   HydWtr_pct_Ammonia  HydWtr_Na2O   DI55152   FC55003       FC55552  \\\n",
            "0            0.908765     2.712180  0.925255  4919.290  41564.100000   \n",
            "1            0.907643     2.805415  0.924281  5039.445  41558.250000   \n",
            "2            0.905959     2.945270  0.923773  5268.620  41524.066667   \n",
            "3            0.904837     3.038505  0.924103  5349.320  41500.275000   \n",
            "4            0.903715     3.131740  0.924258  5563.165  41466.625000   \n",
            "\n",
            "       FC55569  FFC55553  FFC55555    LC55555   PI55004   TC55552     TC55555  \\\n",
            "0  6918.110000  0.996975  0.751501  59.968800  1.306310  177.1880  180.125000   \n",
            "1  6919.960000  0.998847  0.750588  59.932300  1.181220  177.2505  180.053000   \n",
            "2  6916.486667  0.998648  0.750505  60.002433  1.216603  177.4170  180.001667   \n",
            "3  6918.470000  1.000349  0.750325  60.015925  1.206718  177.4590  180.010750   \n",
            "4  6915.790000  1.000862  0.750021  60.020500  1.163892  177.5490  179.939500   \n",
            "\n",
            "      TI55021    Butanol  \n",
            "0  212.861000  54.858300  \n",
            "1  212.699000  51.190050  \n",
            "2  212.822333  48.744567  \n",
            "3  212.799750  46.604750  \n",
            "4  212.853000  44.587220  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "df_TagDesc = pd.read_csv(r'C:\\Users\\saust\\OneDrive\\Desktop\\GitRepo\\Project-OptiC4\\CSV\\Not for Processing\\TagDesc.csv')\n",
        "\n",
        "df_All_1 = pd.read_csv(r'C:\\Users\\saust\\OneDrive\\Desktop\\GitRepo\\Project-OptiC4\\1 Preprocess\\Merge Data\\contData_all_Avg_1o2.csv')\n",
        "df_All_2 = pd.read_csv(r'C:\\Users\\saust\\OneDrive\\Desktop\\GitRepo\\Project-OptiC4\\1 Preprocess\\Merge Data\\contData_all_Avg_2o2.csv')\n",
        "# Concatenate (union) the dataframes\n",
        "df_All = pd.concat([df_All_1, df_All_2], ignore_index=True)\n",
        "\n",
        "print(df_All.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Set max columns to display\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_All = df_All[df_All['Date'] > '2022-06-15 00:00:00']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# # List of columns to exclude to run XGboost feature selection\n",
        "# exclude_columns = ['Octanol', 'Hexanol',\n",
        "#        'Ethanol', 'Decanol',\n",
        "       \n",
        "#        'TI52014', 'TI55013', 'TI55014', 'TI55015', 'TI55016', 'TI55017', 'TI55023',\n",
        "#        # , 'TI55021'\n",
        "\n",
        "#        'TC52015', 'FC52018', 'II52554', 'TI40050', 'VI52558B'\n",
        "\n",
        "#        # 'FC55102', 'FC55152', 'LC55557', 'LC55568', 'TC55555',\n",
        "\n",
        "#        # '425 SAO Al', 'FFC55553', 'LC52572', 'LC90366',\n",
        "\n",
        "#        # 'FC42428', 'LC55553',\n",
        "\n",
        "#        # 'FC55009'\n",
        "#                    ]\n",
        "\n",
        "# # Create a new DataFrame without the excluded columnsd\n",
        "# df_All = df_All.drop(columns=exclude_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['425_pct_Al', 'M_Value', 'C4_pct_Eth', 'C4_pct_H2O', 'C4_pct_Hex',\n",
              "       'HydWtr_pct_Ammonia', 'HydWtr_Na2O', 'DI55152', 'FC55003', 'FC55552',\n",
              "       'FC55569', 'FFC55553', 'FFC55555', 'LC55555', 'PI55004', 'TC55552',\n",
              "       'TC55555', 'TI55021', 'Butanol'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_All.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Splitting into train and test\n",
        "# X = df_All.drop('Butanol', axis=1)  # Assuming 'target' is your target column\n",
        "# y = df_All['Butanol']\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def iterate_feature_rotations(df_all, target_column, test_size=0.2, random_state=42, num_random_iterations=30):\n",
        "    results = []\n",
        "    columns = [col for col in df_all.columns if col != target_column]\n",
        "    random.seed(random_state)  # for reproducibility\n",
        "\n",
        "    for feature in columns:\n",
        "        for _ in range(num_random_iterations):\n",
        "            # Randomly order the remaining features\n",
        "            remaining_features = [f for f in columns if f != feature]\n",
        "            random.shuffle(remaining_features)\n",
        "\n",
        "            # Create a new ordered list of features\n",
        "            ordered_features = [feature] + remaining_features\n",
        "\n",
        "            reordered_df = df_all[ordered_features + [target_column]]\n",
        "\n",
        "            # Splitting into train and test for each permutation\n",
        "            X = reordered_df.drop(target_column, axis=1)\n",
        "            y = reordered_df[target_column]\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "            # Create and fit the XGBoost model\n",
        "            model = xgb.XGBRegressor(objective='reg:squarederror')\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Extract feature importances\n",
        "            feature_importances = model.get_booster().get_score(importance_type=\"weight\")\n",
        "\n",
        "            # Store the result with the permutation order and feature importances\n",
        "            results.append((ordered_features, feature_importances))\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "results = iterate_feature_rotations(df_All, 'Butanol')\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "flattened_results = []\n",
        "for ordered_features, importances in results:\n",
        "    for feature, importance in importances.items():\n",
        "        flattened_results.append({\n",
        "            'Feature Rotation': ordered_features,\n",
        "            'Feature': feature,\n",
        "            'Importance': importance\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(flattened_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                       Feature Rotation             Feature  \\\n",
            "0     [425_pct_Al, FC55003, FFC55553, HydWtr_Na2O, D...          425_pct_Al   \n",
            "1     [425_pct_Al, FC55003, FFC55553, HydWtr_Na2O, D...             FC55003   \n",
            "2     [425_pct_Al, FC55003, FFC55553, HydWtr_Na2O, D...            FFC55553   \n",
            "3     [425_pct_Al, FC55003, FFC55553, HydWtr_Na2O, D...         HydWtr_Na2O   \n",
            "4     [425_pct_Al, FC55003, FFC55553, HydWtr_Na2O, D...             DI55152   \n",
            "...                                                 ...                 ...   \n",
            "9715  [TI55021, C4_pct_Eth, TC55555, LC55555, FFC555...             FC55552   \n",
            "9716  [TI55021, C4_pct_Eth, TC55555, LC55555, FFC555...          C4_pct_Hex   \n",
            "9717  [TI55021, C4_pct_Eth, TC55555, LC55555, FFC555...  HydWtr_pct_Ammonia   \n",
            "9718  [TI55021, C4_pct_Eth, TC55555, LC55555, FFC555...             FC55003   \n",
            "9719  [TI55021, C4_pct_Eth, TC55555, LC55555, FFC555...             PI55004   \n",
            "\n",
            "      Importance  \n",
            "0          540.0  \n",
            "1          314.0  \n",
            "2          324.0  \n",
            "3          351.0  \n",
            "4          356.0  \n",
            "...          ...  \n",
            "9715       233.0  \n",
            "9716       299.0  \n",
            "9717       278.0  \n",
            "9718       178.0  \n",
            "9719       211.0  \n",
            "\n",
            "[9720 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Group by 'Feature' and calculate the average importance\n",
        "average_importances = results_df.groupby('Feature')['Importance'].mean()\n",
        "\n",
        "# Convert the Series to a DataFrame\n",
        "average_importances_df = average_importances.reset_index()\n",
        "\n",
        "# Rename the columns for clarity\n",
        "average_importances_df.columns = ['Feature', 'Average Importance']\n",
        "\n",
        "# Sort the DataFrame by 'Average Importance' in descending order\n",
        "average_importances_df = average_importances_df.sort_values(by='Average Importance', ascending=False)\n",
        "\n",
        "# # Display or save the DataFrame\n",
        "# print(average_importances_df)\n",
        "# # Or save it to a CSV file\n",
        "# # average_importances_df.to_csv('average_feature_importances.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               Feature  Average Importance               Description\n",
            "0              DI55152          357.903704    2ND STG SEPR TO FA-560\n",
            "1           C4_pct_Eth          355.972222                       NaN\n",
            "2              M_Value          355.887037                       NaN\n",
            "3           C4_pct_H2O          353.446296                       NaN\n",
            "4           C4_pct_Hex          340.746296                       NaN\n",
            "5          HydWtr_Na2O          334.937037                       NaN\n",
            "6   HydWtr_pct_Ammonia          330.053704                       NaN\n",
            "7           425_pct_Al          329.918519                       NaN\n",
            "8              FC55569          312.129630    30# STM TO C4 STRIPPER\n",
            "9              TC55552          311.709259  DC-551 ALKOX  FD PREHEAT\n",
            "10            FFC55553          281.283333  DC551 H2O/ALKOXIDE RATIO\n",
            "11             LC55555          274.348148   FA-552 1ST STG SEP SLRY\n",
            "12             FC55552          266.561111  ALK FD TO HYDR RX DC-551\n",
            "13             PI55004          259.757407    DA-554 BOTTOM PRESSURE\n",
            "14            FFC55555          258.451852  RECYC BUT/ALKOX FD RATIO\n",
            "15             FC55003          222.305556  DA-551 O/H H2O TO DC-551\n",
            "16             TC55555          215.409259       EA-552 OUT  RECY C4\n",
            "17             TI55021          193.179630            STEAM TO DA554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\saust\\AppData\\Local\\Temp\\ipykernel_87464\\3091506829.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  final_df.rename(columns={'DESCRIPTION': 'Description'}, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# Merge the average_importances_df with df_TagDesc\n",
        "# Assuming 'ID' in df_TagDesc corresponds to 'Feature' in average_importances_df\n",
        "merged_df = average_importances_df.merge(df_TagDesc, left_on='Feature', right_on='ID', how='left')\n",
        "\n",
        "# Select only the required columns\n",
        "final_df = merged_df[['Feature', 'Average Importance', 'DESCRIPTION']]\n",
        "\n",
        "# Rename the 'DESCRIPTION' column to 'Description'\n",
        "final_df.rename(columns={'DESCRIPTION': 'Description'}, inplace=True)\n",
        "\n",
        "# Display or save the DataFrame\n",
        "print(final_df)\n",
        "# Or save it to a CSV file\n",
        "# final_df.to_csv('average_feature_importances_with_descriptions.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
