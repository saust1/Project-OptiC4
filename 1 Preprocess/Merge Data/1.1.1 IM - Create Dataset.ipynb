{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Set max columns to display\n",
        "pd.set_option('display.max_columns', None)\n",
        "from sklearn import preprocessing as pre\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# Importing CSV files\n",
        "df_CDunit = pd.read_csv(r\"C:\\Users\\saust\\OneDrive\\Desktop\\GitRepo\\Project-OptiC4\\1 Preprocess\\Continuous Data\\cont_554Data_clean.csv\")\n",
        "df_AlCon = pd.read_csv(r\"C:\\Users\\saust\\OneDrive\\Desktop\\GitRepo\\Project-OptiC4\\1 Preprocess\\Continuous Data\\cont_425Data_clean.csv\")\n",
        "df_FB554 = pd.read_csv(r\"C:\\Users\\saust\\OneDrive\\Desktop\\GitRepo\\Project-OptiC4\\1 Preprocess\\Continuous Data\\cont_unitData_clean.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            Butanol\n",
            "count  48064.000000\n",
            "mean       9.785834\n",
            "std       10.160568\n",
            "min        0.000000\n",
            "25%        3.832595\n",
            "50%        5.908670\n",
            "75%       10.990000\n",
            "max       59.010000\n",
            "         425_pct_Al       M_Value    C4_pct_Eth    C4_pct_H2O  \\\n",
            "count  48064.000000  48064.000000  48064.000000  48064.000000   \n",
            "mean       6.121527      3.598034      1.246364     21.103333   \n",
            "std        0.310173      0.180238      0.720948      2.763381   \n",
            "min        0.155707      1.346790      0.086632      7.823650   \n",
            "25%        5.991420      3.500708      0.642266     18.737475   \n",
            "50%        6.131130      3.590000      1.195790     21.332700   \n",
            "75%        6.274265      3.688767      1.697302     23.248450   \n",
            "max        8.058320      5.831770      9.844330     34.362400   \n",
            "\n",
            "       HydWtr_pct_Ammonia  \n",
            "count        48064.000000  \n",
            "mean             0.967209  \n",
            "std              0.146912  \n",
            "min              0.360178  \n",
            "25%              0.875875  \n",
            "50%              0.939325  \n",
            "75%              1.030030  \n",
            "max              1.617070  \n",
            "           AYC55580       DI55102       DI55152       DI55580       FC42428  \\\n",
            "count  48064.000000  48064.000000  48064.000000  48064.000000  48064.000000   \n",
            "mean      11.363177      0.938292      0.936531      0.998257  36151.561639   \n",
            "std        4.850976      0.059909      0.034358      0.051217   5139.441714   \n",
            "min       -3.055680      0.794118      0.824670      0.841696  17165.500000   \n",
            "25%        9.775320      0.906156      0.913999      0.965028  34747.850000   \n",
            "50%       10.805350      0.947357      0.935493      0.997964  37970.750000   \n",
            "75%       13.970725      0.983124      0.955312      1.033820  39457.650000   \n",
            "max       25.501300      1.059180      1.048640      1.140980  49959.600000   \n",
            "\n",
            "            FC55003       FC55009       FC55102       FC55152       FC55552  \\\n",
            "count  48064.000000  48064.000000  48064.000000  48064.000000  48064.000000   \n",
            "mean    5952.978185    848.220753  44526.824994  40417.323864  36340.104550   \n",
            "std      847.683897    610.037366   6168.162983   5459.963811   4275.391282   \n",
            "min     2807.760000      0.000000  20368.700000  18860.700000  18558.800000   \n",
            "25%     5424.630000    320.318250  41409.300000  38485.600000  35062.075000   \n",
            "50%     5973.450000    834.348500  45887.700000  41477.500000  37960.000000   \n",
            "75%     6522.630000   1323.710000  48543.450000  43732.800000  39017.500000   \n",
            "max     9070.260000   2670.920000  62848.200000  57371.200000  52000.000000   \n",
            "\n",
            "            FC55555       FC55569       FC55576      FFC55553      FFC55555  \\\n",
            "count  48064.000000  48064.000000  48064.000000  48064.000000  48064.000000   \n",
            "mean   28104.100489   6596.276391    380.872724      0.998268      0.773248   \n",
            "std     3419.828722    362.422636    259.029411      0.036746      0.022350   \n",
            "min    14012.100000   5145.140000      0.000000      0.815578      0.694477   \n",
            "25%    27282.375000   6379.000000    203.479250      0.972384      0.759308   \n",
            "50%    29231.100000   6577.465000    350.728000      0.997870      0.776544   \n",
            "75%    30205.850000   6805.180000    565.299250      1.018792      0.789198   \n",
            "max    34638.100000   8070.910000   1176.810000      1.170060      0.850961   \n",
            "\n",
            "           FYC55553       LC55553       LC55555       LC55557       LC55568  \\\n",
            "count  48064.000000  48064.000000  48064.000000  48064.000000  48064.000000   \n",
            "mean   36234.197955     63.329273     57.081414     69.431922     41.143177   \n",
            "std     4176.239735      7.156869     10.037618      2.810757      1.498108   \n",
            "min    18110.900000     41.918300     27.970000     60.351700     32.192200   \n",
            "25%    34881.850000     59.578950     47.263450     67.117900     40.742375   \n",
            "50%    37538.800000     65.397850     59.943700     70.031500     41.234850   \n",
            "75%    38838.475000     68.206550     65.086750     71.619725     41.599000   \n",
            "max    46156.700000     82.753500     79.033400     78.119700     49.420800   \n",
            "\n",
            "            LC90366       LC90368       PI55004       PI55020       PI55560  \\\n",
            "count  48064.000000  48064.000000  48064.000000  48064.000000  48064.000000   \n",
            "mean      46.508861     37.532827      2.183574     -1.523616      0.978657   \n",
            "std       28.725663     20.215792      1.166487      1.116584      0.991547   \n",
            "min        0.000000      0.006367      0.001366     -4.856830     -2.094890   \n",
            "25%       22.035575     21.661050      1.262065     -2.386153      0.206120   \n",
            "50%       48.833400     43.461900      1.922580     -1.532940      0.746700   \n",
            "75%       76.796700     52.770625      2.940780     -0.512644      1.657118   \n",
            "max       87.901600     81.210800      6.299380      1.983020      4.467930   \n",
            "\n",
            "            TC55552       TC55553       TC55555       TC55566       TI40050  \\\n",
            "count  48064.000000  48064.000000  48064.000000  48064.000000  48064.000000   \n",
            "mean     168.616937    181.290465    181.008748    197.163834     73.315504   \n",
            "std       15.352568     28.041787      1.515823     12.953080     15.320339   \n",
            "min      119.683000    110.534000    175.746000    156.727000     27.200000   \n",
            "25%      155.332000    161.451000    179.965000    185.858000     62.505400   \n",
            "50%      172.531000    175.799000    180.125000    200.039000     76.556250   \n",
            "75%      180.858250    196.687250    182.027000    205.077000     84.896025   \n",
            "max      202.625000    246.047000    186.584000    227.835000    118.700000   \n",
            "\n",
            "            TI52014       TI55013       TI55014       TI55015       TI55016  \\\n",
            "count  48064.000000  48064.000000  48064.000000  48064.000000  48064.000000   \n",
            "mean     129.077874    200.789109    197.065824    194.719423    190.094731   \n",
            "std       11.973351     17.680867     13.726206     13.604169      9.159624   \n",
            "min       91.769900    161.963000    167.953000    161.407000    164.278000   \n",
            "25%      120.655750    186.294250    186.099750    184.028750    182.823750   \n",
            "50%      129.614500    199.092000    195.789000    193.494500    189.006000   \n",
            "75%      138.056250    210.519000    204.229250    202.010250    194.924000   \n",
            "max      163.594000    241.383000    228.072000    227.543000    213.986000   \n",
            "\n",
            "            TI55017       TI55021       TI55023  \n",
            "count  48064.000000  48064.000000  48064.000000  \n",
            "mean     186.024059    223.081652    218.300526  \n",
            "std        9.817368      9.611556      3.614977  \n",
            "min      159.678000    207.365000    206.266000  \n",
            "25%      178.739750    217.585000    215.524000  \n",
            "50%      185.013000    220.385000    217.590000  \n",
            "75%      191.763500    223.934000    220.830000  \n",
            "max      211.356000    257.805000    231.161000  \n"
          ]
        }
      ],
      "source": [
        "print(df_CDunit.describe())\n",
        "print(df_AlCon.describe())\n",
        "print(df_FB554.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data type for 'Date' column in df_CDunit: object\n",
            "Data type for 'Date' column in df_FB554: object\n",
            "Data type for 'Date' column in df_AlCon: object\n"
          ]
        }
      ],
      "source": [
        "print(\"Data type for 'Date' column in df_CDunit:\", df_CDunit['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_FB554:\", df_FB554['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_AlCon:\", df_AlCon['Date'].dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_CDunit['Date'] = pd.to_datetime(df_CDunit['Date'], errors='coerce')\n",
        "df_FB554['Date'] = pd.to_datetime(df_FB554['Date'], errors='coerce')\n",
        "df_AlCon['Date'] = pd.to_datetime(df_AlCon['Date'], errors='coerce')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data type for 'Date' column in df_CDunit: datetime64[ns]\n",
            "Data type for 'Date' column in df_FB554: datetime64[ns]\n",
            "Data type for 'Date' column in df_AlCon: datetime64[ns]\n"
          ]
        }
      ],
      "source": [
        "print(\"Data type for 'Date' column in df_CDunit:\", df_CDunit['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_FB554:\", df_FB554['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_AlCon:\", df_AlCon['Date'].dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Date', 'Butanol'], dtype='object')\n",
            "Index(['Date', 'AYC55580', 'DI55102', 'DI55152', 'DI55580', 'FC42428',\n",
            "       'FC55003', 'FC55009', 'FC55102', 'FC55152', 'FC55552', 'FC55555',\n",
            "       'FC55569', 'FC55576', 'FFC55553', 'FFC55555', 'FYC55553', 'LC55553',\n",
            "       'LC55555', 'LC55557', 'LC55568', 'LC90366', 'LC90368', 'PI55004',\n",
            "       'PI55020', 'PI55560', 'TC55552', 'TC55553', 'TC55555', 'TC55566',\n",
            "       'TI40050', 'TI52014', 'TI55013', 'TI55014', 'TI55015', 'TI55016',\n",
            "       'TI55017', 'TI55021', 'TI55023'],\n",
            "      dtype='object')\n",
            "Index(['Date', '425_pct_Al', 'M_Value', 'C4_pct_Eth', 'C4_pct_H2O',\n",
            "       'HydWtr_pct_Ammonia'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df_CDunit.columns)\n",
        "print(df_FB554.columns)\n",
        "print(df_AlCon.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_rolling_average_to_df(df, rolling_size):\n",
        "    # Ensure 'Date' is the index if it's not already\n",
        "    if df.index.name != 'Date':\n",
        "        df = df.set_index('Date')\n",
        "\n",
        "    # Apply rolling average to all columns\n",
        "    rolled_df = df.rolling(window=rolling_size, min_periods=1).mean()\n",
        "\n",
        "    # Reset index to make 'Date' a column again\n",
        "    rolled_df = rolled_df.reset_index()\n",
        "\n",
        "    return rolled_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_time_shift_by_hours(df, shift_hours):\n",
        "    \"\"\"\n",
        "    Shifts the DataFrame's datetime index by the specified number of hours.\n",
        "\n",
        "    :param df: DataFrame with 'Date' as its datetime index or column.\n",
        "    :param shift_hours: Number of hours to shift. Can be positive (forward) or negative (backward).\n",
        "    :return: Shifted DataFrame.\n",
        "    \"\"\"\n",
        "    # Convert 'Date' to datetime and set as index if it's not already\n",
        "    if df.index.name != 'Date':\n",
        "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "        df = df.set_index('Date')\n",
        "\n",
        "    # Ensure the index is a DatetimeIndex\n",
        "    df.index = pd.to_datetime(df.index)\n",
        "\n",
        "    # Shift the DataFrame's index by the specified number of hours\n",
        "    df.index = df.index + pd.Timedelta(hours=shift_hours)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Usage Examples\n",
        "# shift_hours_AlCon = 1  # Negative shift for df_AlCon (e.g., -5 hours backward)\n",
        "# shift_hours_FB554 = 5   # Positive shift for df_FB554 (e.g., 5 hours forward)\n",
        "\n",
        "# shifted_df_AlCon = apply_time_shift_by_hours(df_AlCon, shift_hours_AlCon)\n",
        "# print(\"Shifted df_AlCon:\")\n",
        "# print(shifted_df_AlCon.head())\n",
        "\n",
        "# shifted_df_FB554 = apply_time_shift_by_hours(df_FB554, shift_hours_FB554)\n",
        "# print(\"\\nShifted df_FB554:\")\n",
        "# print(shifted_df_FB554.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def join_df_FB554_to_df_CDunit(df_CDunit, df_FB554):\n",
        "    # Ensure 'Date' columns are datetime objects and sort DataFrames\n",
        "    df_CDunit['Date'] = pd.to_datetime(df_CDunit['Date'], errors='coerce')\n",
        "    df_FB554['Date'] = pd.to_datetime(df_FB554['Date'], errors='coerce')\n",
        "\n",
        "    df_CDunit = df_CDunit.dropna(subset=['Date']).sort_values('Date')\n",
        "    df_FB554 = df_FB554.dropna(subset=['Date']).sort_values('Date')\n",
        "\n",
        "    # Perform merge_asof\n",
        "    combined_df = pd.merge_asof(df_FB554, df_CDunit, on='Date', direction='nearest')\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "def join_df_AlCon_to_combined_df(combined_df, df_AlCon):\n",
        "    # Ensure 'Date' columns are datetime objects and sort DataFrames\n",
        "    combined_df['Date'] = pd.to_datetime(combined_df['Date'], errors='coerce')\n",
        "    df_AlCon['Date'] = pd.to_datetime(df_AlCon['Date'], errors='coerce')\n",
        "\n",
        "    combined_df = combined_df.dropna(subset=['Date']).sort_values('Date')\n",
        "    df_AlCon = df_AlCon.dropna(subset=['Date']).sort_values('Date')\n",
        "\n",
        "    # Perform merge_asof\n",
        "    combined_df_all = pd.merge_asof(df_AlCon, combined_df, on='Date', direction='nearest')\n",
        "    \n",
        "    return combined_df_all\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data type for 'Date' column in df_CDunit: datetime64[ns]\n",
            "Data type for 'Date' column in df_FB554: datetime64[ns]\n",
            "Data type for 'Date' column in df_AlCon: datetime64[ns]\n"
          ]
        }
      ],
      "source": [
        "print(\"Data type for 'Date' column in df_CDunit:\", df_CDunit['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_FB554:\", df_FB554['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_AlCon:\", df_AlCon['Date'].dtypes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Iterative merger \n",
        "# avereaged F stat\n",
        "# filtered two closest f stats by whole number\n",
        "# Took the best adj R^2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\saust\\AppData\\Local\\Temp\\ipykernel_113672\\2705700377.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results = results.append(iteration_results, ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "def apply_negative_shift_hours(shift_hours):\n",
        "    return [-hour for hour in shift_hours]\n",
        "\n",
        "# Rolling sizes ranges\n",
        "rolling_size_CDunit = [8]  # Even rolling sizes from 4 to 10 range(4, 11, 2)\n",
        "rolling_size_FB554 = [4]  # Even rolling sizes from 4 to 10 range(4, 11, 2)\n",
        "rolling_size_AlCon = [2]  # Even rolling sizes from 2 to 30 range(2, 31, 2) \n",
        "\n",
        "# Shift hours ranges\n",
        "shift_hours_AlCon = apply_negative_shift_hours([1])  # Negative shifts from -2 to -8 (range(2, 9, 2)) \n",
        "shift_hours_FB554 = ([1])    # Positive shifts from 2 to 8 range(2, 9, 2)\n",
        "\n",
        "# Precompute rolling averages for each DataFrame and each rolling size\n",
        "precomputed_rolls = {\n",
        "    \"CDunit\": {size: apply_rolling_average_to_df(df_CDunit, size) for size in rolling_size_CDunit},\n",
        "    \"FB554\": {size: apply_rolling_average_to_df(df_FB554, size) for size in rolling_size_FB554},\n",
        "    \"AlCon\": {size: apply_rolling_average_to_df(df_AlCon, size) for size in rolling_size_AlCon}\n",
        "}\n",
        "\n",
        "## Modified process_data function\n",
        "def process_data():\n",
        "    iteration_count = 0\n",
        "    results = pd.DataFrame(columns=['Iteration', 'Rolling Sizes CDunit', 'Rolling Sizes FB554', 'Rolling Sizes AlCon',\n",
        "                                    'Shift Hours AlCon', 'Shift Hours FB554', 'R-squared', 'Adj R-Squared', \n",
        "                                    'F-statistic', 'Prob (F-statistic)'])\n",
        "    all_combined_dfs = []  # List to store combined_df_all for each iteration\n",
        "\n",
        "    for size_CDunit in rolling_size_CDunit:\n",
        "        for size_FB554 in rolling_size_FB554:\n",
        "            for size_AlCon in rolling_size_AlCon:\n",
        "                for shift_hour_AlCon in shift_hours_AlCon:\n",
        "                    for shift_hour_FB554 in shift_hours_FB554:\n",
        "                        iteration_count += 1\n",
        "\n",
        "                        # Retrieve rolled dataframes\n",
        "                        rolled_df_CDunit = precomputed_rolls[\"CDunit\"][size_CDunit]\n",
        "                        rolled_df_FB554 = precomputed_rolls[\"FB554\"][size_FB554]\n",
        "                        rolled_df_AlCon = precomputed_rolls[\"AlCon\"][size_AlCon]\n",
        "\n",
        "                        # Combine df_CDunit and df_FB554 to create combined_df\n",
        "                        combined_df = join_df_FB554_to_df_CDunit(rolled_df_CDunit, rolled_df_FB554)\n",
        "\n",
        "                        # Combine combined_df with rolled_df_AlCon to create combined_df_all\n",
        "                        combined_df_all = join_df_AlCon_to_combined_df(combined_df, rolled_df_AlCon)\n",
        "\n",
        "                        # Drop 'Date' column before modeling\n",
        "                        combined_df_all = combined_df_all.drop(columns=['Date'], errors='ignore')\n",
        "\n",
        "                        # Store combined_df_all in the list\n",
        "                        all_combined_dfs.append(combined_df_all)\n",
        "\n",
        "                        # Splitting into train and test\n",
        "                        X = combined_df_all.drop('Butanol', axis=1)\n",
        "                        y = combined_df_all['Butanol']\n",
        "                        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "                        # Train model\n",
        "                        model = sm.OLS(y_train, X_train).fit()\n",
        "\n",
        "                        # Store the results instead of printing\n",
        "                        iteration_results = {\n",
        "                            'Iteration': iteration_count,\n",
        "                            'Rolling Sizes CDunit': size_CDunit,\n",
        "                            'Rolling Sizes FB554': size_FB554,\n",
        "                            'Rolling Sizes AlCon': size_AlCon,\n",
        "                            'Shift Hours AlCon': shift_hour_AlCon,\n",
        "                            'Shift Hours FB554': shift_hour_FB554,\n",
        "                            'R-squared': model.rsquared,\n",
        "                            'Adj R-Squared': model.rsquared_adj,\n",
        "                            'F-statistic': model.fvalue,\n",
        "                            'Prob (F-statistic)': model.f_pvalue\n",
        "                        }\n",
        "                        results = results.append(iteration_results, ignore_index=True)\n",
        "\n",
        "                        # Print only the iteration count\n",
        "                        print(f\"Iteration: {iteration_count}\")\n",
        "\n",
        "    return results, all_combined_dfs  # Return both results and the list of combined_df_all\n",
        "\n",
        "# Call the function to process and evaluate the data\n",
        "model_results, all_combined_dfs = process_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save DataFrame to CSV file in the same directory as the Jupyter Notebook\n",
        "model_results.to_csv('model_results2.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_df_all = pd.concat(all_combined_dfs)\n",
        "\n",
        "# Assuming combined_df_all is your DataFrame\n",
        "\n",
        "# Calculate the index to split the DataFrame\n",
        "split_index = len(combined_df_all) // 2\n",
        "\n",
        "# Split the DataFrame into two parts\n",
        "df_part1 = combined_df_all.iloc[:split_index]\n",
        "df_part2 = combined_df_all.iloc[split_index:]\n",
        "\n",
        "# Save the two parts to CSV\n",
        "df_part1.to_csv('contData_all_Avg_1o2.csv', index=False)\n",
        "df_part2.to_csv('contData_all_Avg_2o2.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
