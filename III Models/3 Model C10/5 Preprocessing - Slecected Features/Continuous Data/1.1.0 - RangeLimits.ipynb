{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Set max columns to display\n",
        "pd.set_option('display.max_columns', None)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importing CSV files\n",
        "\n",
        "\n",
        "# df_adjust_Limits = pd.read_csv('https://raw.githubusercontent.com/saust1/Project-OptiC4/main/1%20Preprocess/Continuous%20Data/contData_all.csv')\n",
        "\n",
        "# df_adjustments = pd.read_csv('https://raw.githubusercontent.com/saust1/Project-OptiC4/main/CSV/PVs/adjust_limits.csv')\n",
        "\n",
        "\n",
        "df_adjust_Limits = pd.read_csv(r\"C:\\Users\\austinsh\\Project-OptiC4\\III Models\\3 Model C10\\5 Preprocessing - Slecected Features\\Continuous Data\\contData_all.csv\")\n",
        "\n",
        "df_adjustments = pd.read_csv(r\"C:\\Users\\austinsh\\Project-OptiC4\\II Data\\1 Collection\\CSV\\PVs\\adjust_limits.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_columns = df_adjust_Limits.shape[1]\n",
        "print(\"Number of features:\", num_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# # Convert 'Date' column to datetime in df_adjust_Limits and df_LD using the appropriate format\n",
        "# df_adjust_Limits['Date'] = pd.to_datetime(df_adjust_Limits['Date'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
        "\n",
        "# # Check for NaT entries in both dataframes\n",
        "# nat_count_CD = df_adjust_Limits['Date'].isna().sum()\n",
        "\n",
        "df_adjust_Limits.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Annotate all range adjustements with rationale\n",
        "\n",
        "#df_adjustments = pd.read_csv(r\"C:\\Users\\saust\\OneDrive - Sasol\\1 Project rC4\\Data\\CSV to PRocess\\RangeD.csv\")\n",
        "df_adjustments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Finds and removes system limit (Min/Max) values\n",
        "\n",
        "# Assuming df_adjustments and df_adjust_Limits are your dataframes\n",
        "\n",
        "# Extract the min and max rows from df_adjustments into separate Series\n",
        "min_values = df_adjustments[df_adjustments['Range'] == 'Min'].iloc[0, 1:]\n",
        "max_values = df_adjustments[df_adjustments['Range'] == 'Max'].iloc[0, 1:]\n",
        "\n",
        "# Iterate through each column in df_adjust_Limits\n",
        "for col in df_adjust_Limits.columns:\n",
        "    # Check if the column exists in df_adjustments\n",
        "    if col in min_values.index:\n",
        "        # Get the min and max values for this column from df_adjustments\n",
        "        min_val = min_values[col]\n",
        "        max_val = max_values[col]\n",
        "        \n",
        "        # Filter out values in df_adjust_Limits that are less than min or greater than max\n",
        "        df_adjust_Limits.loc[df_adjust_Limits[col] < min_val, col] = None\n",
        "        df_adjust_Limits.loc[df_adjust_Limits[col] > max_val, col] = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a binary matrix to represent NaNs (1 for NaN, 0 for a number)\n",
        "nan_matrix = np.where(df_adjust_Limits.isna(), 1, 0)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 10))  # Adjust the size as needed\n",
        "cmap = plt.get_cmap('viridis', 2)  # We use a colormap that differentiates between 0 and 1 clearly\n",
        "\n",
        "# Plotting heatmap\n",
        "cax = ax.imshow(nan_matrix, cmap=cmap, aspect='auto')\n",
        "\n",
        "# Adding colorbar for reference\n",
        "plt.colorbar(cax, ticks=[0, 1], label='NaN Presence')\n",
        "plt.title(\"NaN Presence in Data (1 for NaN, 0 for Not NaN)\", pad=20)\n",
        "\n",
        "# To make the columns readable and vertical\n",
        "plt.xticks(range(df_adjust_Limits.shape[1]), df_adjust_Limits.columns, rotation=90)  # rotation set to 90 for vertical labels\n",
        "\n",
        "plt.xlabel('Columns')\n",
        "plt.ylabel('Row Index')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the statistics for each column in df_adjust_Limits\n",
        "total_rows = len(df_adjust_Limits)\n",
        "non_nan_count = df_adjust_Limits.count()\n",
        "nan_count = df_adjust_Limits.isnull().sum()\n",
        "nan_percentage = (nan_count / total_rows) * 100\n",
        "\n",
        "# Store these in a DataFrame\n",
        "nan_stats = pd.DataFrame({\n",
        "    'ID': df_adjust_Limits.columns,\n",
        "    'total_rows': total_rows,\n",
        "    'non_nan_count': non_nan_count.values,\n",
        "    'nan_count': nan_count.values,\n",
        "    'nan_percentage': nan_percentage.values\n",
        "})\n",
        "\n",
        "print(nan_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Analysis of remaining NaNs suggests minimal impact - REMOVE\n",
        "\n",
        "df_adjust_Limits = df_adjust_Limits.dropna()\n",
        "\n",
        "# Calculate the statistics for each column in df_pivot\n",
        "total_rows = len(df_adjust_Limits)\n",
        "non_nan_count = df_adjust_Limits.count()\n",
        "nan_count = df_adjust_Limits.isnull().sum()\n",
        "nan_percentage = (nan_count / total_rows) * 100\n",
        "\n",
        "# Store these in a DataFrame\n",
        "nan_stats = pd.DataFrame({\n",
        "    'ID': df_adjust_Limits.columns,\n",
        "    'total_rows': total_rows,\n",
        "    'non_nan_count': non_nan_count.values,\n",
        "    'nan_count': nan_count.values,\n",
        "    'nan_percentage': nan_percentage.values\n",
        "})\n",
        "\n",
        "print(nan_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 59840 Records with all features included for preprocessing\n",
        "\n",
        "df_adjust_Limits = df_adjust_Limits.sort_values('Date')\n",
        "df_adjust_Limits = df_adjust_Limits.reset_index(drop=True)\n",
        "\n",
        "\n",
        "# Save DataFrame to CSV file in the same directory as the Jupyter Notebook\n",
        "# df_adjust_Limits.to_csv(r'C:\\Users\\steve\\OneDrive\\1. BAIUTEK\\Project-OptiC4\\1 Preprocess\\Continuous Data\\adjusted_Limits.csv', index=False)\n",
        "\n",
        "#bordeCode\n",
        "df_adjust_Limits.to_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\III Models\\3 Model C10\\5 Preprocessing - Slecected Features\\Continuous Data\\adjusted_Limits.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_adjust_Limits.describe()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 59840 Records with all features included for preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Get the current date and time\n",
        "current_date_time = datetime.now()\n",
        "\n",
        "# Print the current date and time\n",
        "print(current_date_time)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
