{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install statsmodels\n",
        "# %pip install mlxtend\n",
        "# %pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.formula.api import ols\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import random\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                  Date  425_pct_Al     Al2O3  M_Value  C4_pct_Eth  C4_pct_H2O  \\\n",
            "0  2012-05-17 09:00:00    6.319560  11.41670  3.50773    2.554580     22.0531   \n",
            "1  2012-05-17 10:00:00    6.319915  11.40835  3.50797    2.555935     22.0557   \n",
            "2  2012-05-17 12:00:00    6.320970  11.39165  3.50869    2.560005     22.0636   \n",
            "3  2012-05-18 08:00:00    6.328690  11.39165  3.51401    2.540370     22.0604   \n",
            "4  2012-05-18 09:00:00    6.336060  11.40500  3.51910    2.514430     22.0484   \n",
            "\n",
            "   HydWtr_pct_Ammonia  C4_pct_Hex  HydWtr_Na2O  Butanol  ...    LC90366  \\\n",
            "0            0.867508    0.670721     3.354160  30.3662  ...  15.449150   \n",
            "1            0.864729    0.671059     3.306475  30.3662  ...  15.449150   \n",
            "2            0.856391    0.672071     3.163420  30.6785  ...  15.449150   \n",
            "3            0.811652    0.674174     2.238130  32.6454  ...   8.759814   \n",
            "4            0.773793    0.675408     1.391475  32.6454  ...   8.759814   \n",
            "\n",
            "    LC90368   PI55004   PI55020   TC55552   TC55553   TC55555   TI40050  \\\n",
            "0  49.26750  1.236360 -0.389406  179.0115  213.9375  179.9940  82.96565   \n",
            "1  49.26750  1.236360 -0.389406  179.0115  213.9375  179.9940  82.96565   \n",
            "2  49.26750  1.236360 -0.389406  179.0115  213.9375  179.9940  82.96565   \n",
            "3  48.51306  1.190342 -0.318266  180.7166  201.0680  179.9338  82.41662   \n",
            "4  48.51306  1.190342 -0.318266  180.7166  201.0680  179.9338  82.41662   \n",
            "\n",
            "    TI55021   TI55023  \n",
            "0  213.8740  212.3085  \n",
            "1  213.8740  212.3085  \n",
            "2  213.8740  212.3085  \n",
            "3  214.5402  212.9866  \n",
            "4  214.5402  212.9866  \n",
            "\n",
            "[5 rows x 33 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df_TagDesc = pd.read_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\II Data\\1 Collection\\CSV\\Not for Processing\\TagDesc.csv')\n",
        "\n",
        "# df_All_1 = pd.read_csv(r'C:\\Users\\saust\\OneDrive\\Desktop\\GitRepo\\Project-OptiC4\\1 Preprocess\\Merge Data\\contData_all_Avg_1o2.csv')\n",
        "# df_All_2 = pd.read_csv(r'C:\\Users\\saust\\OneDrive\\Desktop\\GitRepo\\Project-OptiC4\\1 Preprocess\\Merge Data\\contData_all_Avg_2o2.csv')\n",
        "# # Concatenate (union) the dataframes\n",
        "# df_All = pd.concat([df_All_1, df_All_2], ignore_index=True)\n",
        "\n",
        "df_All = pd.read_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\III Models\\3 Model C10\\3 Feature Selection\\filtered-out_5-9_corr.csv')\n",
        "\n",
        "print(df_All.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Set max columns to display\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_All = df_All[df_All['Date'] > '2022-06-15 00:00:00']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# # List of columns to exclude to run XGboost feature selection\n",
        "# exclude_columns = ['Octanol', 'Hexanol',\n",
        "#        'Ethanol', 'Decanol',\n",
        "       \n",
        "#        'TI52014', 'TI55013', 'TI55014', 'TI55015', 'TI55016', 'TI55017', 'TI55023',\n",
        "#        # , 'TI55021'\n",
        "\n",
        "#        'TC52015', 'FC52018', 'II52554', 'TI40050', 'VI52558B'\n",
        "\n",
        "#        # 'FC55102', 'FC55152', 'LC55557', 'LC55568', 'TC55555',\n",
        "\n",
        "#        # '425 SAO Al', 'FFC55553', 'LC52572', 'LC90366',\n",
        "\n",
        "#        # 'FC42428', 'LC55553',\n",
        "\n",
        "#        # 'FC55009'\n",
        "#                    ]\n",
        "\n",
        "# # Create a new DataFrame without the excluded columnsd\n",
        "# df_All = df_All.drop(columns=exclude_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Date', '425_pct_Al', 'Al2O3', 'M_Value', 'C4_pct_Eth', 'C4_pct_H2O',\n",
              "       'HydWtr_pct_Ammonia', 'C4_pct_Hex', 'HydWtr_Na2O', 'Butanol', 'DI55102',\n",
              "       'DI55152', 'DI55580', 'FC55003', 'FC55552', 'FC55569', 'FC55576',\n",
              "       'FFC55553', 'FFC55555', 'LC52572', 'LC55553', 'LC55557', 'LC55568',\n",
              "       'LC90366', 'LC90368', 'PI55004', 'PI55020', 'TC55552', 'TC55553',\n",
              "       'TC55555', 'TI40050', 'TI55021', 'TI55023'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_All.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Splitting into train and test\n",
        "# X = df_All.drop('Butanol', axis=1)  # Assuming 'target' is your target column\n",
        "# y = df_All['Butanol']\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def iterate_feature_rotations(df_all, target_column, test_size=0.2, random_state=42, num_random_iterations=30):\n",
        "    results = []\n",
        "    columns = [col for col in df_all.columns if col != target_column and col != 'Date']\n",
        "    random.seed(random_state)  # for reproducibility\n",
        "\n",
        "    for feature in columns:\n",
        "        for _ in range(num_random_iterations):\n",
        "            # Randomly order the remaining features\n",
        "            remaining_features = [f for f in columns if f != feature]\n",
        "            random.shuffle(remaining_features)\n",
        "\n",
        "            # Create a new ordered list of features\n",
        "            ordered_features = [feature] + remaining_features\n",
        "\n",
        "            reordered_df = df_all[ordered_features + [target_column]]\n",
        "\n",
        "            # Splitting into train and test for each permutation\n",
        "            X = reordered_df.drop(target_column, axis=1)\n",
        "            y = reordered_df[target_column]\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "            # Create and fit the XGBoost model\n",
        "            model = xgb.XGBRegressor(objective='reg:squarederror')\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Extract feature importances\n",
        "            feature_importances = model.get_booster().get_score(importance_type=\"weight\")\n",
        "\n",
        "            # Store the result with the permutation order and feature importances\n",
        "            results.append((ordered_features, feature_importances))\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "results = iterate_feature_rotations(df_All, 'Butanol')\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "flattened_results = []\n",
        "for ordered_features, importances in results:\n",
        "    for feature, importance in importances.items():\n",
        "        flattened_results.append({\n",
        "            'Feature Rotation': ordered_features,\n",
        "            'Feature': feature,\n",
        "            'Importance': importance\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(flattened_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                        Feature Rotation     Feature  \\\n",
            "0      [425_pct_Al, LC55568, FFC55553, FC55003, TC555...  425_pct_Al   \n",
            "1      [425_pct_Al, LC55568, FFC55553, FC55003, TC555...     LC55568   \n",
            "2      [425_pct_Al, LC55568, FFC55553, FC55003, TC555...    FFC55553   \n",
            "3      [425_pct_Al, LC55568, FFC55553, FC55003, TC555...     FC55003   \n",
            "4      [425_pct_Al, LC55568, FFC55553, FC55003, TC555...     TC55555   \n",
            "...                                                  ...         ...   \n",
            "28825  [TI55023, TI40050, DI55102, DI55152, TC55553, ...     LC90366   \n",
            "28826  [TI55023, TI40050, DI55102, DI55152, TC55553, ...     FC55576   \n",
            "28827  [TI55023, TI40050, DI55102, DI55152, TC55553, ...     TC55552   \n",
            "28828  [TI55023, TI40050, DI55102, DI55152, TC55553, ...     FC55552   \n",
            "28829  [TI55023, TI40050, DI55102, DI55152, TC55553, ...  425_pct_Al   \n",
            "\n",
            "       Importance  \n",
            "0           493.0  \n",
            "1           222.0  \n",
            "2           237.0  \n",
            "3           218.0  \n",
            "4           170.0  \n",
            "...           ...  \n",
            "28825       153.0  \n",
            "28826       155.0  \n",
            "28827       172.0  \n",
            "28828       158.0  \n",
            "28829       154.0  \n",
            "\n",
            "[28830 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Group by 'Feature' and calculate the average importance\n",
        "average_importances = results_df.groupby('Feature')['Importance'].mean()\n",
        "\n",
        "# Convert the Series to a DataFrame\n",
        "average_importances_df = average_importances.reset_index()\n",
        "\n",
        "# Rename the columns for clarity\n",
        "average_importances_df.columns = ['Feature', 'Average Importance']\n",
        "\n",
        "# Sort the DataFrame by 'Average Importance' in descending order\n",
        "average_importances_df = average_importances_df.sort_values(by='Average Importance', ascending=False)\n",
        "\n",
        "# # Display or save the DataFrame\n",
        "# print(average_importances_df)\n",
        "# # Or save it to a CSV file\n",
        "# # average_importances_df.to_csv('average_feature_importances.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               Feature  Average Importance                Description\n",
            "0   HydWtr_pct_Ammonia          227.722581                        NaN\n",
            "1          HydWtr_Na2O          212.411828                        NaN\n",
            "2              TC55552          207.874194   DC-551 ALKOX  FD PREHEAT\n",
            "3              FC55569          197.351613     30# STM TO C4 STRIPPER\n",
            "4           C4_pct_H2O          196.354839                        NaN\n",
            "5           425_pct_Al          192.492473                        NaN\n",
            "6              FC55003          191.511828   DA-551 O/H H2O TO DC-551\n",
            "7              LC90368          187.060215       FB-658 ALKOXIDE TANK\n",
            "8           C4_pct_Hex          186.644086                        NaN\n",
            "9              FC55552          185.907527   ALK FD TO HYDR RX DC-551\n",
            "10          C4_pct_Eth          185.891398                        NaN\n",
            "11            FFC55553          182.823656   DC551 H2O/ALKOXIDE RATIO\n",
            "12             LC55557          182.505376        FA-554 SLURRY LEVEL\n",
            "13             FC55576          181.621505   CONDENSATE TO DESUPERHTR\n",
            "14             DI55102          181.230108           HYDROL RX OUTLET\n",
            "15             M_Value          180.132258                        NaN\n",
            "16             LC90366          172.938710         FB-657 SAO STORAGE\n",
            "17             LC52572          171.348387   FB-554 SLURRY SURGE TANK\n",
            "18             DI55152          170.191398     2ND STG SEPR TO FA-560\n",
            "19             DI55580          160.326882   DA-554 BTMS SLURRY TO EX\n",
            "20               Al2O3          157.970968                        NaN\n",
            "21            FFC55555          154.272043   RECYC BUT/ALKOX FD RATIO\n",
            "22             TC55555          152.260215        EA-552 OUT  RECY C4\n",
            "23             PI55020          151.460215        DA-554 TOP PRESSURE\n",
            "24             TC55553          148.665591    DC-551 HYDR H2O PREHEAT\n",
            "25             TI55021          147.448387             STEAM TO DA554\n",
            "26             LC55553          147.170968   DC551 HYDR RX SLURRY LEV\n",
            "27             LC55568          146.126882    DA-554 C4 STRPR BOTTOMS\n",
            "28             TI40050          141.439785  CLARK AIR COMP INLET TEMP\n",
            "29             TI55023          108.291398                        NaN\n",
            "30             PI55004          100.552688     DA-554 BOTTOM PRESSURE\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\austinsh\\AppData\\Local\\Temp\\ipykernel_19100\\3091506829.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  final_df.rename(columns={'DESCRIPTION': 'Description'}, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# Merge the average_importances_df with df_TagDesc\n",
        "# Assuming 'ID' in df_TagDesc corresponds to 'Feature' in average_importances_df\n",
        "merged_df = average_importances_df.merge(df_TagDesc, left_on='Feature', right_on='ID', how='left')\n",
        "\n",
        "# Select only the required columns\n",
        "final_df = merged_df[['Feature', 'Average Importance', 'DESCRIPTION']]\n",
        "\n",
        "# Rename the 'DESCRIPTION' column to 'Description'\n",
        "final_df.rename(columns={'DESCRIPTION': 'Description'}, inplace=True)\n",
        "\n",
        "# Display or save the DataFrame\n",
        "print(final_df)\n",
        "# Or save it to a CSV file\n",
        "# final_df.to_csv('average_feature_importances_with_descriptions.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-19 19:58:48.507877\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Get the current date and time\n",
        "current_date_time = datetime.now()\n",
        "\n",
        "# Print the current date and time\n",
        "print(current_date_time)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
