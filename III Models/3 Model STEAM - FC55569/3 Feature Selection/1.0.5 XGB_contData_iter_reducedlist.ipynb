{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install statsmodels\n",
        "# %pip install mlxtend\n",
        "# %pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\austinsh\\AppData\\Local\\Temp\\ipykernel_46440\\526159370.py:2: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.formula.api import ols\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import random\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                  Date  425_pct_Al     Al2O3  M_Value  C4_pct_Eth  C4_pct_H2O  \\\n",
            "0  2012-05-17 09:00:00    6.319560  11.41670  3.50773    2.554580     22.0531   \n",
            "1  2012-05-17 10:00:00    6.319915  11.40835  3.50797    2.555935     22.0557   \n",
            "2  2012-05-17 12:00:00    6.320970  11.39165  3.50869    2.560005     22.0636   \n",
            "3  2012-05-18 08:00:00    6.328690  11.39165  3.51401    2.540370     22.0604   \n",
            "4  2012-05-18 09:00:00    6.336060  11.40500  3.51910    2.514430     22.0484   \n",
            "\n",
            "   HydWtr_pct_Ammonia  C4_pct_Hex  HydWtr_Na2O  Butanol  ...    LC90366  \\\n",
            "0            0.867508    0.670721     3.354160  30.3662  ...  15.449150   \n",
            "1            0.864729    0.671059     3.306475  30.3662  ...  15.449150   \n",
            "2            0.856391    0.672071     3.163420  30.6785  ...  15.449150   \n",
            "3            0.811652    0.674174     2.238130  32.6454  ...   8.759814   \n",
            "4            0.773793    0.675408     1.391475  32.6454  ...   8.759814   \n",
            "\n",
            "    LC90368   PI55004   PI55020   TC55552   TC55553   TC55555   TI40050  \\\n",
            "0  49.26750  1.236360 -0.389406  179.0115  213.9375  179.9940  82.96565   \n",
            "1  49.26750  1.236360 -0.389406  179.0115  213.9375  179.9940  82.96565   \n",
            "2  49.26750  1.236360 -0.389406  179.0115  213.9375  179.9940  82.96565   \n",
            "3  48.51306  1.190342 -0.318266  180.7166  201.0680  179.9338  82.41662   \n",
            "4  48.51306  1.190342 -0.318266  180.7166  201.0680  179.9338  82.41662   \n",
            "\n",
            "    TI55021   TI55023  \n",
            "0  213.8740  212.3085  \n",
            "1  213.8740  212.3085  \n",
            "2  213.8740  212.3085  \n",
            "3  214.5402  212.9866  \n",
            "4  214.5402  212.9866  \n",
            "\n",
            "[5 rows x 33 columns]\n"
          ]
        }
      ],
      "source": [
        "# df_All_1 = pd.read_csv(r'C:\\Users\\saust\\OneDrive\\Desktop\\GitRepo\\Project-OptiC4\\1 Preprocess\\Merge Data\\contData_all_Avg_1o2.csv')\n",
        "# df_All_2 = pd.read_csv(r'C:\\Users\\saust\\OneDrive\\Desktop\\GitRepo\\Project-OptiC4\\1 Preprocess\\Merge Data\\contData_all_Avg_2o2.csv')\n",
        "# # Concatenate (union) the dataframes\n",
        "# df_All = pd.concat([df_All_1, df_All_2], ignore_index=True)\n",
        "\n",
        "df_All = pd.read_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\III Models\\3 Model C10\\3 Feature Selection\\filtered-out_5-9_corr.csv')\n",
        "print(df_All.head())\n",
        "\n",
        "df_TagDesc = pd.read_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\II Data\\1 Collection\\CSV\\Not for Processing\\TagDesc.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Set max columns to display\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_All = df_All[df_All['Date'] > '2022-06-15 00:00:00']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# selected_columns = ['Butanol', \n",
        "#                     'FC55569',\n",
        "#                     'DI55152',\n",
        "#                     '425 %Al',\n",
        "#                     'TC55552',\n",
        "#                     'FC55003',\n",
        "#                     'LC55555',\n",
        "#                     'FFC55553',\n",
        "#                     'FFC55555',\n",
        "#                     'TC55555',\n",
        "#                     'TI55021',\n",
        "#                     'PI55004',\n",
        "#                     'FC55552'\n",
        "#                     ]\n",
        "# existing_columns = [col for col in selected_columns if col in df_All.columns]\n",
        "# df_All = df_All[existing_columns]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # List of columns to exclude to run XGboost feature selection\n",
        "exclude_columns = [\n",
        "                'TI40050',\n",
        "                'TC55555',\n",
        "                'LC55568',\n",
        "                'LC55557',\n",
        "                'Al2O3',\n",
        "                'LC55553',\n",
        "\n",
        "        # 'Octanol', 'Hexanol',\n",
        "#        'Ethanol', 'Decanol',\n",
        "       \n",
        "#        'TI52014', 'TI55013', 'TI55014', 'TI55015', 'TI55016', 'TI55017', 'TI55021', 'TI55023',\n",
        "#        'TC52015', 'FC52018', 'II52554', 'TI40050', 'VI52558B'\n",
        "\n",
        "#        # 'FC55102', 'FC55152', 'LC55557', 'LC55568', 'TC55555',\n",
        "\n",
        "#        # '425 SAO Al', 'FFC55553', 'LC52572', 'LC90366',\n",
        "\n",
        "#        # 'FC42428', 'LC55553',\n",
        "\n",
        "#        # 'FC55009'\n",
        "                   ]\n",
        "\n",
        "# # Create a new DataFrame without the excluded columnsd\n",
        "df_All = df_All.drop(columns=exclude_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Date', '425_pct_Al', 'Al2O3', 'M_Value', 'C4_pct_Eth', 'C4_pct_H2O',\n",
              "       'HydWtr_pct_Ammonia', 'C4_pct_Hex', 'HydWtr_Na2O', 'Butanol', 'DI55102',\n",
              "       'DI55152', 'DI55580', 'FC55003', 'FC55552', 'FC55569', 'FC55576',\n",
              "       'FFC55553', 'FFC55555', 'LC52572', 'LC55557', 'LC90366', 'LC90368',\n",
              "       'TC55552'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_All.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Splitting into train and test\n",
        "# X = df_All.drop('Butanol', axis=1)  # Assuming 'target' is your target column\n",
        "# y = df_All['Butanol']\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def iterate_feature_rotations(df_all, target_column, test_size=0.2, random_state=42, num_random_iterations=30):\n",
        "    results = []\n",
        "    columns = [col for col in df_all.columns if col != target_column and col != 'Date']\n",
        "    random.seed(random_state)  # for reproducibility\n",
        "\n",
        "    for feature in columns:\n",
        "        for _ in range(num_random_iterations):\n",
        "            # Randomly order the remaining features\n",
        "            remaining_features = [f for f in columns if f != feature]\n",
        "            random.shuffle(remaining_features)\n",
        "\n",
        "            # Create a new ordered list of features\n",
        "            ordered_features = [feature] + remaining_features\n",
        "\n",
        "            reordered_df = df_all[ordered_features + [target_column]]\n",
        "\n",
        "            # Splitting into train and test for each permutation\n",
        "            X = reordered_df.drop(target_column, axis=1)\n",
        "            y = reordered_df[target_column]\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "            # Create and fit the XGBoost model\n",
        "            model = xgb.XGBRegressor(objective='reg:squarederror')\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Extract feature importances\n",
        "            feature_importances = model.get_booster().get_score(importance_type=\"weight\")\n",
        "\n",
        "            # Store the result with the permutation order and feature importances\n",
        "            results.append((ordered_features, feature_importances))\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "results = iterate_feature_rotations(df_All, 'Decanol')\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "flattened_results = []\n",
        "for ordered_features, importances in results:\n",
        "    for feature, importance in importances.items():\n",
        "        flattened_results.append({\n",
        "            'Feature Rotation': ordered_features,\n",
        "            'Feature': feature,\n",
        "            'Importance': importance\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(flattened_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                        Feature Rotation             Feature  \\\n",
            "0      [425_pct_Al, LC90368, C4_pct_Hex, FFC55553, Hy...          425_pct_Al   \n",
            "1      [425_pct_Al, LC90368, C4_pct_Hex, FFC55553, Hy...             LC90368   \n",
            "2      [425_pct_Al, LC90368, C4_pct_Hex, FFC55553, Hy...          C4_pct_Hex   \n",
            "3      [425_pct_Al, LC90368, C4_pct_Hex, FFC55553, Hy...            FFC55553   \n",
            "4      [425_pct_Al, LC90368, C4_pct_Hex, FFC55553, Hy...  HydWtr_pct_Ammonia   \n",
            "...                                                  ...                 ...   \n",
            "14515  [TC55552, LC90366, 425_pct_Al, LC52572, FC5500...             DI55102   \n",
            "14516  [TC55552, LC90366, 425_pct_Al, LC52572, FC5500...            FFC55555   \n",
            "14517  [TC55552, LC90366, 425_pct_Al, LC52572, FC5500...             FC55569   \n",
            "14518  [TC55552, LC90366, 425_pct_Al, LC52572, FC5500...          C4_pct_Hex   \n",
            "14519  [TC55552, LC90366, 425_pct_Al, LC52572, FC5500...               Al2O3   \n",
            "\n",
            "       Importance  \n",
            "0           507.0  \n",
            "1           340.0  \n",
            "2           243.0  \n",
            "3           250.0  \n",
            "4           312.0  \n",
            "...           ...  \n",
            "14515       197.0  \n",
            "14516       187.0  \n",
            "14517       193.0  \n",
            "14518       166.0  \n",
            "14519       192.0  \n",
            "\n",
            "[14520 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Group by 'Feature' and calculate the average importance\n",
        "average_importances = results_df.groupby('Feature')['Importance'].mean()\n",
        "\n",
        "# Convert the Series to a DataFrame\n",
        "average_importances_df = average_importances.reset_index()\n",
        "\n",
        "# Rename the columns for clarity\n",
        "average_importances_df.columns = ['Feature', 'Average Importance']\n",
        "\n",
        "# Sort the DataFrame by 'Average Importance' in descending order\n",
        "average_importances_df = average_importances_df.sort_values(by='Average Importance', ascending=False)\n",
        "\n",
        "# Display or save the DataFrame\n",
        "# print(average_importances_df)\n",
        "# Or save it to a CSV file\n",
        "# average_importances_df.to_csv('average_feature_importances.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               Feature  Average Importance               Description\n",
            "0   HydWtr_pct_Ammonia          284.618182                       NaN\n",
            "1              TC55552          276.412121  DC-551 ALKOX  FD PREHEAT\n",
            "2          HydWtr_Na2O          266.648485                       NaN\n",
            "3           C4_pct_H2O          256.862121                       NaN\n",
            "4              FC55552          255.525758  ALK FD TO HYDR RX DC-551\n",
            "5           C4_pct_Eth          253.631818                       NaN\n",
            "6              LC90368          249.543939      FB-658 ALKOXIDE TANK\n",
            "7              FC55003          246.583333  DA-551 O/H H2O TO DC-551\n",
            "8              DI55152          245.648485    2ND STG SEPR TO FA-560\n",
            "9           425_pct_Al          239.277273                       NaN\n",
            "10             LC55557          238.777273       FA-554 SLURRY LEVEL\n",
            "11             FC55576          236.889394  CONDENSATE TO DESUPERHTR\n",
            "12             DI55102          235.024242          HYDROL RX OUTLET\n",
            "13             FC55569          234.300000    30# STM TO C4 STRIPPER\n",
            "14             LC90366          234.178788        FB-657 SAO STORAGE\n",
            "15            FFC55555          225.686364  RECYC BUT/ALKOX FD RATIO\n",
            "16             M_Value          223.860606                       NaN\n",
            "17            FFC55553          214.578788  DC551 H2O/ALKOXIDE RATIO\n",
            "18             DI55580          213.721212  DA-554 BTMS SLURRY TO EX\n",
            "19               Al2O3          209.865152                       NaN\n",
            "20          C4_pct_Hex          205.965152                       NaN\n",
            "21             LC52572          203.401515  FB-554 SLURRY SURGE TANK\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\austinsh\\AppData\\Local\\Temp\\ipykernel_46440\\3091506829.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  final_df.rename(columns={'DESCRIPTION': 'Description'}, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# Merge the average_importances_df with df_TagDesc\n",
        "# Assuming 'ID' in df_TagDesc corresponds to 'Feature' in average_importances_df\n",
        "merged_df = average_importances_df.merge(df_TagDesc, left_on='Feature', right_on='ID', how='left')\n",
        "\n",
        "# Select only the required columns\n",
        "final_df = merged_df[['Feature', 'Average Importance', 'DESCRIPTION']]\n",
        "\n",
        "# Rename the 'DESCRIPTION' column to 'Description'\n",
        "final_df.rename(columns={'DESCRIPTION': 'Description'}, inplace=True)\n",
        "\n",
        "# Display or save the DataFrame\n",
        "print(final_df)\n",
        "# Or save it to a CSV file\n",
        "# final_df.to_csv('average_feature_importances_with_descriptions.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-20 23:50:22.650111\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Get the current date and time\n",
        "current_date_time = datetime.now()\n",
        "\n",
        "# Print the current date and time\n",
        "print(current_date_time)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
