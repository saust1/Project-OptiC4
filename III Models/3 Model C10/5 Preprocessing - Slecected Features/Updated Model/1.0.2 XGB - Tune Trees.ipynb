{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import cross_val_score, KFold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# df_TagDesc = pd.read_csv(r'C:\\Users\\saust\\OneDrive\\Desktop\\GitRepo\\Project-OptiC4\\CSV\\Not for Processing\\TagDesc.csv')\n",
        "\n",
        "# df_All_1 = pd.read_csv(r'C:\\Users\\saust\\OneDrive\\Desktop\\GitRepo\\Project-OptiC4\\1 Preprocess\\Merge Data\\contData_all_Avg_1o2.csv')\n",
        "# df_All_2 = pd.read_csv(r'C:\\Users\\saust\\OneDrive\\Desktop\\GitRepo\\Project-OptiC4\\1 Preprocess\\Merge Data\\contData_all_Avg_2o2.csv')\n",
        "# # Concatenate (union) the dataframes\n",
        "# df_All = pd.concat([df_All_1, df_All_2], ignore_index=True)\n",
        "\n",
        "df_All = pd.read_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\III Models\\3 Model C10\\5 Preprocessing - Slecected Features\\Merge Data\\merged_data.csv')\n",
        "\n",
        "print(df_All.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Set max columns to display\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # # List of columns to exclude from the XGboost feature selection results\n",
        "# exclude_columns = [\n",
        "#                     'TI40050',\n",
        "#                     'TC55555',\n",
        "#                     'LC55568',\n",
        "#                     'LC55557',\n",
        "#                     'Al2O3',\n",
        "#                     'LC55553',\n",
        "#                     'M_Value',\n",
        "#                     'FFC55553',\n",
        "#                     'DI55580',\n",
        "#                     'Al2O3',\n",
        "#                     'C4_pct_Hex',\n",
        "#                     'LC52572',\n",
        "\n",
        "# #                  'Date',\n",
        "# #                  'C4_pct_Hex', 'HydWtr_Na2O',\n",
        "# #                  'TC55555'  \n",
        "#                    ]\n",
        "\n",
        "# # # Create a new DataFrame without the excluded columnsd\n",
        "# df_All = df_All.drop(columns=exclude_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_All.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_All = df_All[df_All['Date'] > '2020-06-15 00:00:00']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_All.drop('Date', axis=1, inplace=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_All.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming your data is in filtered_df and you want to predict 'target_column_name'\n",
        "X = df_All.drop(['Decanol', 'Date'], axis=1)  # Replace 'target_column_name' with your target column's name\n",
        "y = df_All['Decanol']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and train the XGBoost Regressor\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    objective ='reg:squarederror', \n",
        "    learning_rate=0.05,\n",
        "    n_estimators=800,\n",
        "    max_depth=10,\n",
        "    subsample=0.6,\n",
        "    colsample_bytree=1,\n",
        "    gamma=0,\n",
        "    alpha=0.1,\n",
        "    reg_lambda=1.5,\n",
        "    colsample_bylevel=0.8,\n",
        "    colsample_bynode=0.7\n",
        ")\n",
        "xgb_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict on training data\n",
        "y_train_pred = xgb_model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on training data\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "print(f\"Mean Squared Error on Training Data: {mse_train}\")\n",
        "\n",
        "\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error on the Testing Data: {mse}\")\n",
        "\n",
        "rmse_train = np.sqrt(mse_train)\n",
        "print(f\"Root Mean Squared Error on Training Data: {rmse_train}\")\n",
        "\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"Root Mean Squared Error on the Testing Data: {rmse}\")\n",
        "\n",
        "# Calculate R-squared\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "print(f\"R-squared value on Training Data:: {r2_train:.2f}\")\n",
        "\n",
        "\n",
        "# Calculate R-squared\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R-squared value on the Testing Data: {r2:.2f}\")\n",
        "\n",
        "current_features = X.columns.tolist()\n",
        "\n",
        "# Calculate Adjusted R-squared\n",
        "def adjusted_r2(r2, n, k):\n",
        "    \"\"\"\n",
        "    Compute the adjusted R^2 from R^2, number of samples (n) and number of predictors (k).\n",
        "    \n",
        "    Args:\n",
        "    - r2 (float): R^2 value\n",
        "    - n (int): number of samples\n",
        "    - k (int): number of predictors\n",
        "\n",
        "    Returns:\n",
        "    - float: adjusted R^2 value\n",
        "    \"\"\"\n",
        "    return 1 - (1 - r2) * (n - 1) / (n - k - 1)\n",
        "\n",
        "\n",
        "adj_r2 = adjusted_r2(r2, len(y_test), len(current_features))\n",
        "\n",
        "print(f\"Adjusted R^2 value: {adj_r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs. Predicted')\n",
        "\n",
        "# Calculate the min and max values across both y_test and y_pred\n",
        "min_val = min(min(y_test), min(y_pred))\n",
        "max_val = max(max(y_test), max(y_pred))\n",
        "\n",
        "# Plot the red 1:1 line\n",
        "plt.plot([min_val, max_val], [min_val, max_val], color='red')  # 1:1 line\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "residuals = y_test - y_pred\n",
        "plt.scatter(y_pred, residuals)\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_rows = df_All.shape[0]\n",
        "\n",
        "splits = num_rows//10000\n",
        "\n",
        "if splits < 5:\n",
        "    splits = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the K-fold cross validator\n",
        "kfold = KFold(n_splits=splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform K-fold cross-validation\n",
        "scores = cross_val_score(xgb_model, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Take the square root of the scores to get the RMSE\n",
        "rmse_scores = np.sqrt(-scores)\n",
        "\n",
        "# Print out the results\n",
        "print(f'Scores for each fold are: {rmse_scores}')\n",
        "print(f'Average RMSE: {np.mean(rmse_scores)}')\n",
        "print(f'Standard deviation of RMSE: {np.std(rmse_scores)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_All.columns"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
