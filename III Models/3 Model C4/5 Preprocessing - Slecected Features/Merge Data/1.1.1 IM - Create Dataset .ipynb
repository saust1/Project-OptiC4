{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\austinsh\\AppData\\Local\\Temp\\ipykernel_4284\\1304120184.py:1: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Set max columns to display\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import preprocessing as pre\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Importing CSV files\n",
        "# df_CDunit = pd.read_csv('https://raw.githubusercontent.com/saust1/Project-OptiC4/main/1%20Preprocess/Continuous%20Data/cont_554Data_clean.csv')\n",
        "# df_AlCon = pd.read_csv('https://raw.githubusercontent.com/saust1/Project-OptiC4/main/1%20Preprocess/Continuous%20Data/cont_425Data_clean.csv')\n",
        "# df_FB554 = pd.read_csv('https://raw.githubusercontent.com/saust1/Project-OptiC4/main/1%20Preprocess/Continuous%20Data/cont_unitData_clean.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Importing CSV files\n",
        "# bordeCode directory\n",
        "df_CDunit = pd.read_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\III Models\\3 Model C4\\5 Preprocessing - Slecected Features\\Continuous Data\\cont_unitData_clean.csv')\n",
        "df_AlCon = pd.read_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\III Models\\3 Model C4\\5 Preprocessing - Slecected Features\\Continuous Data\\cont_425Data_clean.csv')\n",
        "df_FB554 = pd.read_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\III Models\\3 Model C4\\5 Preprocessing - Slecected Features\\Continuous Data\\cont_554Data_clean.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            DI55102       DI55152       FC55552       FC55569       FC55576  \\\n",
            "count  50412.000000  50412.000000  50412.000000  50412.000000  50412.000000   \n",
            "mean       0.944181      0.933228  35894.540348   6604.659472    368.223212   \n",
            "std        0.054264      0.030261   5062.928860    391.775333    256.823627   \n",
            "min        0.800002      0.837031  17996.100000   5135.670000      0.000000   \n",
            "25%        0.909903      0.912872  34928.575000   6367.697500    187.706750   \n",
            "50%        0.950058      0.933519  37958.600000   6585.025000    340.072500   \n",
            "75%        0.985276      0.952969  39020.800000   6824.470000    548.285500   \n",
            "max        1.061510      1.025180  52000.000000   8114.690000   1132.440000   \n",
            "\n",
            "           FFC55553      FFC55555       LC55557       LC90366       LC90368  \\\n",
            "count  50412.000000  50412.000000  50412.000000  50412.000000  50412.000000   \n",
            "mean       1.000855      0.771996     69.444867     46.383755     36.483942   \n",
            "std        0.037820      0.022996      2.913241     28.994092     20.119883   \n",
            "min        0.811764      0.689689     60.061400      0.000000      0.006367   \n",
            "25%        0.977031      0.758525     66.887075     21.497850     20.074150   \n",
            "50%        0.998706      0.773389     70.082700     47.940250     41.592000   \n",
            "75%        1.020160      0.788061     71.738075     77.046100     51.752025   \n",
            "max        1.178320      0.857842     78.477100     87.901600     81.210800   \n",
            "\n",
            "            TC55552  \n",
            "count  50412.000000  \n",
            "mean     168.849778  \n",
            "std       15.203394  \n",
            "min      119.840000  \n",
            "25%      155.814500  \n",
            "50%      172.744500  \n",
            "75%      180.849250  \n",
            "max      202.625000  \n",
            "         425_pct_Al    C4_pct_Eth    C4_pct_H2O  HydWtr_pct_Ammonia  \\\n",
            "count  50412.000000  50412.000000  50412.000000        50412.000000   \n",
            "mean       6.149348      1.216325     21.191892            0.971065   \n",
            "std        0.254883      0.711173      2.751276            0.153447   \n",
            "min        5.175720      0.009510      8.012620            0.350000   \n",
            "25%        6.007325      0.626273     18.827625            0.875999   \n",
            "50%        6.143745      1.096440     21.464200            0.941573   \n",
            "75%        6.292922      1.679992     23.341025            1.034320   \n",
            "max        7.136170     12.110300     34.783400            1.631470   \n",
            "\n",
            "         C4_pct_Hex   HydWtr_Na2O  \n",
            "count  50412.000000  50412.000000  \n",
            "mean       0.463719      0.805144  \n",
            "std        0.240083      0.695142  \n",
            "min        0.000060      0.000000  \n",
            "25%        0.346208      0.452928  \n",
            "50%        0.441621      0.662465  \n",
            "75%        0.540207      0.981289  \n",
            "max        3.131310     12.882300  \n",
            "            Butanol\n",
            "count  50412.000000\n",
            "mean       9.839466\n",
            "std       10.203218\n",
            "min        0.000000\n",
            "25%        3.850000\n",
            "50%        5.900000\n",
            "75%       11.000600\n",
            "max       58.786900\n"
          ]
        }
      ],
      "source": [
        "print(df_CDunit.describe())\n",
        "print(df_AlCon.describe())\n",
        "print(df_FB554.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data type for 'Date' column in df_CDunit: object\n",
            "Data type for 'Date' column in df_FB554: object\n",
            "Data type for 'Date' column in df_AlCon: object\n"
          ]
        }
      ],
      "source": [
        "print(\"Data type for 'Date' column in df_CDunit:\", df_CDunit['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_FB554:\", df_FB554['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_AlCon:\", df_AlCon['Date'].dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_CDunit['Date'] = pd.to_datetime(df_CDunit['Date'], errors='coerce')\n",
        "df_FB554['Date'] = pd.to_datetime(df_FB554['Date'], errors='coerce')\n",
        "df_AlCon['Date'] = pd.to_datetime(df_AlCon['Date'], errors='coerce')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data type for 'Date' column in df_CDunit: datetime64[ns]\n",
            "Data type for 'Date' column in df_FB554: datetime64[ns]\n",
            "Data type for 'Date' column in df_AlCon: datetime64[ns]\n"
          ]
        }
      ],
      "source": [
        "print(\"Data type for 'Date' column in df_CDunit:\", df_CDunit['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_FB554:\", df_FB554['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_AlCon:\", df_AlCon['Date'].dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Date', 'DI55102', 'DI55152', 'FC55552', 'FC55569', 'FC55576',\n",
            "       'FFC55553', 'FFC55555', 'LC55557', 'LC90366', 'LC90368', 'TC55552'],\n",
            "      dtype='object')\n",
            "Index(['Date', 'Butanol'], dtype='object')\n",
            "Index(['Date', '425_pct_Al', 'C4_pct_Eth', 'C4_pct_H2O', 'HydWtr_pct_Ammonia',\n",
            "       'C4_pct_Hex', 'HydWtr_Na2O'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df_CDunit.columns)\n",
        "print(df_FB554.columns)\n",
        "print(df_AlCon.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_rolling_average_to_df(df, rolling_size):\n",
        "    # Ensure 'Date' is the index if it's not already\n",
        "    if df.index.name != 'Date':\n",
        "        df = df.set_index('Date')\n",
        "\n",
        "    # Apply rolling average to all columns\n",
        "    rolled_df = df.rolling(window=rolling_size, min_periods=1).mean()\n",
        "\n",
        "    # Reset index to make 'Date' a column again\n",
        "    rolled_df = rolled_df.reset_index()\n",
        "\n",
        "    return rolled_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_time_shift_by_hours(df, shift_hours):\n",
        "    \"\"\"\n",
        "    Shifts the DataFrame's datetime index by the specified number of hours.\n",
        "\n",
        "    :param df: DataFrame with 'Date' as its datetime index or column.\n",
        "    :param shift_hours: Number of hours to shift. Can be positive (forward) or negative (backward).\n",
        "    :return: Shifted DataFrame.\n",
        "    \"\"\"\n",
        "    # Convert 'Date' to datetime and set as index if it's not already\n",
        "    if df.index.name != 'Date':\n",
        "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "        df = df.set_index('Date')\n",
        "\n",
        "    # Ensure the index is a DatetimeIndex\n",
        "    df.index = pd.to_datetime(df.index)\n",
        "\n",
        "    # Shift the DataFrame's index by the specified number of hours\n",
        "    df.index = df.index + pd.Timedelta(hours=shift_hours)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Usage Examples\n",
        "# shift_hours_AlCon = 1  # Negative shift for df_AlCon (e.g., -5 hours backward)\n",
        "# shift_hours_FB554 = 5   # Positive shift for df_FB554 (e.g., 5 hours forward)\n",
        "\n",
        "# shifted_df_AlCon = apply_time_shift_by_hours(df_AlCon, shift_hours_AlCon)\n",
        "# print(\"Shifted df_AlCon:\")\n",
        "# print(shifted_df_AlCon.head())\n",
        "\n",
        "# shifted_df_FB554 = apply_time_shift_by_hours(df_FB554, shift_hours_FB554)\n",
        "# print(\"\\nShifted df_FB554:\")\n",
        "# print(shifted_df_FB554.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def join_df_FB554_to_df_CDunit(df_CDunit, df_FB554):\n",
        "    # Reset index if 'Date' is the index\n",
        "    if df_CDunit.index.name == 'Date':\n",
        "        df_CDunit = df_CDunit.reset_index()\n",
        "    if df_FB554.index.name == 'Date':\n",
        "        df_FB554 = df_FB554.reset_index()\n",
        "\n",
        "    # Ensure 'Date' columns are datetime objects and sort DataFrames\n",
        "    df_CDunit['Date'] = pd.to_datetime(df_CDunit['Date'], errors='coerce')\n",
        "    df_FB554['Date'] = pd.to_datetime(df_FB554['Date'], errors='coerce')\n",
        "\n",
        "    df_CDunit = df_CDunit.dropna(subset=['Date']).sort_values('Date')\n",
        "    df_FB554 = df_FB554.dropna(subset=['Date']).sort_values('Date')\n",
        "\n",
        "    # Perform merge_asof\n",
        "    combined_df = pd.merge_asof(df_FB554, df_CDunit, on='Date', direction='nearest')\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "def join_df_AlCon_to_combined_df(combined_df, df_AlCon):\n",
        "    # Reset index if 'Date' is the index\n",
        "    if combined_df.index.name == 'Date':\n",
        "        combined_df = combined_df.reset_index()\n",
        "    if df_AlCon.index.name == 'Date':\n",
        "        df_AlCon = df_AlCon.reset_index()\n",
        "\n",
        "    # Ensure 'Date' columns are datetime objects and sort DataFrames\n",
        "    combined_df['Date'] = pd.to_datetime(combined_df['Date'], errors='coerce')\n",
        "    df_AlCon['Date'] = pd.to_datetime(df_AlCon['Date'], errors='coerce')\n",
        "\n",
        "    combined_df = combined_df.dropna(subset=['Date']).sort_values('Date')\n",
        "    df_AlCon = df_AlCon.dropna(subset=['Date']).sort_values('Date')\n",
        "\n",
        "    # Perform merge_asof\n",
        "    combined_df_all = pd.merge_asof(df_AlCon, combined_df, on='Date', direction='nearest')\n",
        "    \n",
        "    return combined_df_all\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data type for 'Date' column in df_CDunit: datetime64[ns]\n",
            "Data type for 'Date' column in df_FB554: datetime64[ns]\n",
            "Data type for 'Date' column in df_AlCon: datetime64[ns]\n"
          ]
        }
      ],
      "source": [
        "print(\"Data type for 'Date' column in df_CDunit:\", df_CDunit['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_FB554:\", df_FB554['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_AlCon:\", df_AlCon['Date'].dtypes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_data_limited():\n",
        "    # Apply the specific rolling average directly\n",
        "    rolled_df_CDunit = apply_rolling_average_to_df(df_CDunit, 8)\n",
        "    rolled_df_FB554 = apply_rolling_average_to_df(df_FB554, 4)\n",
        "    rolled_df_AlCon = apply_rolling_average_to_df(df_AlCon, 2)\n",
        "\n",
        "    # Apply the specific time shifts directly\n",
        "    rolled_df_AlCon_shifted = apply_time_shift_by_hours(rolled_df_AlCon, -1) # Assuming apply_time_shift_by_hours handles negative shifts correctly\n",
        "    rolled_df_FB554_shifted = apply_time_shift_by_hours(rolled_df_FB554, 1)\n",
        "\n",
        "    # Combine df_CDunit and df_FB554 to create combined_df\n",
        "    combined_df = join_df_FB554_to_df_CDunit(rolled_df_CDunit, rolled_df_FB554_shifted)\n",
        "\n",
        "    # Combine combined_df with rolled_df_AlCon to create combined_df_all\n",
        "    combined_df_all = join_df_AlCon_to_combined_df(combined_df, rolled_df_AlCon_shifted)\n",
        "\n",
        "    # At this point, combined_df_all is the DataFrame with the data processed by the specified shifts and averages\n",
        "    return combined_df_all\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 Date  425_pct_Al  C4_pct_Eth  C4_pct_H2O  HydWtr_pct_Ammonia  \\\n",
            "0 2012-05-16 15:00:00    6.306930    2.505710    21.95810            0.909887   \n",
            "1 2012-05-16 16:00:00    6.307280    2.507065    21.96075            0.909326   \n",
            "2 2012-05-16 18:00:00    6.308335    2.511135    21.96865            0.907643   \n",
            "3 2012-05-16 19:00:00    6.309390    2.515210    21.97655            0.905959   \n",
            "4 2012-05-16 20:00:00    6.310090    2.517925    21.98185            0.904837   \n",
            "\n",
            "   C4_pct_Hex  HydWtr_Na2O    Butanol   DI55102   DI55152   FC55552   FC55569  \\\n",
            "0    0.658581     2.618940  58.526500  0.970151  0.924718  41476.45  6915.395   \n",
            "1    0.658918     2.665560  58.526500  0.970151  0.924718  41476.45  6915.395   \n",
            "2    0.659930     2.805415  56.692400  0.970151  0.924718  41476.45  6915.395   \n",
            "3    0.660942     2.945270  56.692400  0.970151  0.924718  41476.45  6915.395   \n",
            "4    0.661616     3.038505  53.635533  0.970441  0.923875  41490.25  6915.535   \n",
            "\n",
            "     FC55576  FFC55553  FFC55555    LC55557    LC90366   LC90368    TC55552  \n",
            "0  338.08450  0.998497  0.751216  65.844650  62.291900  51.34935  177.18800  \n",
            "1  338.08450  0.998497  0.751216  65.844650  62.291900  51.34935  177.18800  \n",
            "2  338.08450  0.998497  0.751216  65.844650  62.291900  51.34935  177.18800  \n",
            "3  338.08450  0.998497  0.751216  65.844650  62.291900  51.34935  177.18800  \n",
            "4  334.65925  0.998991  0.750611  65.922175  58.413975  51.01720  177.35975  \n"
          ]
        }
      ],
      "source": [
        "# Make sure all your helper functions and initial DataFrames (df_CDunit, df_FB554, df_AlCon) are correctly defined\n",
        "\n",
        "# Now, call the modified process_data function to get the processed DataFrame\n",
        "final_dataset = process_data_limited()\n",
        "\n",
        "# Inspect the final_dataset\n",
        "print(final_dataset.head())  # Print the first few rows to inspect the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save DataFrame to CSV file in the same directory as the Jupyter Notebook\n",
        "# model_results.to_csv('merged_data'.csv', index=False)\n",
        "                     \n",
        "# Save DataFrame to CSV file in the same directory as the Jupyter Notebook\n",
        "# df_CD.to_csv(r'C:\\Users\\steve\\OneDrive\\1. BAIUTEK\\Project-OptiC4\\1 Preprocess\\Continuous Data\\contData_all.csv', index=False)            \n",
        "\n",
        "final_dataset.to_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\III Models\\3 Model C4\\5 Preprocessing - Slecected Features\\Merge Data\\merged_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-05-06 22:14:06.655151\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Get the current date and time\n",
        "current_date_time = datetime.now()\n",
        "\n",
        "# Print the current date and time\n",
        "print(current_date_time)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
