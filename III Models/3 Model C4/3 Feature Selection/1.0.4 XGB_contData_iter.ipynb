{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install statsmodels\n",
        "# %pip install mlxtend\n",
        "# %pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\austinsh\\AppData\\Local\\Temp\\ipykernel_18976\\526159370.py:2: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.formula.api import ols\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import random\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                  Date  425_pct_Al     Al2O3  M_Value  C4_pct_Eth  C4_pct_H2O  \\\n",
            "0  2012-05-17 09:00:00    6.319560  11.41670  3.50773    2.554580     22.0531   \n",
            "1  2012-05-17 10:00:00    6.319915  11.40835  3.50797    2.555935     22.0557   \n",
            "2  2012-05-17 12:00:00    6.320970  11.39165  3.50869    2.560005     22.0636   \n",
            "3  2012-05-18 08:00:00    6.328690  11.39165  3.51401    2.540370     22.0604   \n",
            "4  2012-05-18 09:00:00    6.336060  11.40500  3.51910    2.514430     22.0484   \n",
            "\n",
            "   HydWtr_pct_Ammonia  C4_pct_Hex  HydWtr_Na2O  Butanol  ...   LC55568  \\\n",
            "0            0.867508    0.670721     3.354160  30.3662  ...  40.25250   \n",
            "1            0.864729    0.671059     3.306475  30.3662  ...  40.25250   \n",
            "2            0.856391    0.672071     3.163420  30.6785  ...  40.25250   \n",
            "3            0.811652    0.674174     2.238130  32.6454  ...  39.88364   \n",
            "4            0.773793    0.675408     1.391475  32.6454  ...  39.88364   \n",
            "\n",
            "     LC90366   LC90368   PI55004   PI55020   TC55552   TC55553   TC55555  \\\n",
            "0  15.449150  49.26750  1.236360 -0.389406  179.0115  213.9375  179.9940   \n",
            "1  15.449150  49.26750  1.236360 -0.389406  179.0115  213.9375  179.9940   \n",
            "2  15.449150  49.26750  1.236360 -0.389406  179.0115  213.9375  179.9940   \n",
            "3   8.759814  48.51306  1.190342 -0.318266  180.7166  201.0680  179.9338   \n",
            "4   8.759814  48.51306  1.190342 -0.318266  180.7166  201.0680  179.9338   \n",
            "\n",
            "    TI40050   TI55021  \n",
            "0  82.96565  213.8740  \n",
            "1  82.96565  213.8740  \n",
            "2  82.96565  213.8740  \n",
            "3  82.41662  214.5402  \n",
            "4  82.41662  214.5402  \n",
            "\n",
            "[5 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df_TagDesc = pd.read_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\II Data\\1 Collection\\CSV\\Not for Processing\\TagDesc.csv')\n",
        "\n",
        "# df_All_1 = pd.read_csv(r'C:\\Users\\saust\\OneDrive\\Desktop\\GitRepo\\Project-OptiC4\\1 Preprocess\\Merge Data\\contData_all_Avg_1o2.csv')\n",
        "# df_All_2 = pd.read_csv(r'C:\\Users\\saust\\OneDrive\\Desktop\\GitRepo\\Project-OptiC4\\1 Preprocess\\Merge Data\\contData_all_Avg_2o2.csv')\n",
        "# # Concatenate (union) the dataframes\n",
        "# df_All = pd.concat([df_All_1, df_All_2], ignore_index=True)\n",
        "\n",
        "df_All = pd.read_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\III Models\\3 Model C4\\3 Feature Selection\\filtered-out_5-9_corr.csv')\n",
        "\n",
        "print(df_All.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Set max columns to display\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_All = df_All[df_All['Date'] > '2022-06-15 00:00:00']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# # List of columns to exclude to run XGboost feature selection\n",
        "# exclude_columns = ['Octanol', 'Hexanol',\n",
        "#        'Ethanol', 'Decanol',\n",
        "       \n",
        "#        'TI52014', 'TI55013', 'TI55014', 'TI55015', 'TI55016', 'TI55017', 'TI55023',\n",
        "#        # , 'TI55021'\n",
        "\n",
        "#        'TC52015', 'FC52018', 'II52554', 'TI40050', 'VI52558B'\n",
        "\n",
        "#        # 'FC55102', 'FC55152', 'LC55557', 'LC55568', 'TC55555',\n",
        "\n",
        "#        # '425 SAO Al', 'FFC55553', 'LC52572', 'LC90366',\n",
        "\n",
        "#        # 'FC42428', 'LC55553',\n",
        "\n",
        "#        # 'FC55009'\n",
        "#                    ]\n",
        "\n",
        "# # Create a new DataFrame without the excluded columnsd\n",
        "# df_All = df_All.drop(columns=exclude_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Date', '425_pct_Al', 'Al2O3', 'M_Value', 'C4_pct_Eth', 'C4_pct_H2O',\n",
              "       'HydWtr_pct_Ammonia', 'C4_pct_Hex', 'HydWtr_Na2O', 'Butanol', 'DI55102',\n",
              "       'DI55152', 'DI55580', 'FC55003', 'FC55552', 'FC55569', 'FC55576',\n",
              "       'FFC55553', 'FFC55555', 'LC52572', 'LC55553', 'LC55557', 'LC55568',\n",
              "       'LC90366', 'LC90368', 'PI55004', 'PI55020', 'TC55552', 'TC55553',\n",
              "       'TC55555', 'TI40050', 'TI55021'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_All.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Splitting into train and test\n",
        "# X = df_All.drop('Butanol', axis=1)  # Assuming 'target' is your target column\n",
        "# y = df_All['Butanol']\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def iterate_feature_rotations(df_all, target_column, test_size=0.2, random_state=42, num_random_iterations=30):\n",
        "    results = []\n",
        "    columns = [col for col in df_all.columns if col != target_column and col != 'Date']\n",
        "    random.seed(random_state)  # for reproducibility\n",
        "\n",
        "    for feature in columns:\n",
        "        for _ in range(num_random_iterations):\n",
        "            # Randomly order the remaining features\n",
        "            remaining_features = [f for f in columns if f != feature]\n",
        "            random.shuffle(remaining_features)\n",
        "\n",
        "            # Create a new ordered list of features\n",
        "            ordered_features = [feature] + remaining_features\n",
        "\n",
        "            reordered_df = df_all[ordered_features + [target_column]]\n",
        "\n",
        "            # Splitting into train and test for each permutation\n",
        "            X = reordered_df.drop(target_column, axis=1)\n",
        "            y = reordered_df[target_column]\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "            # Create and fit the XGBoost model\n",
        "            model = xgb.XGBRegressor(objective='reg:squarederror')\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Extract feature importances\n",
        "            feature_importances = model.get_booster().get_score(importance_type=\"weight\")\n",
        "\n",
        "            # Store the result with the permutation order and feature importances\n",
        "            results.append((ordered_features, feature_importances))\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "results = iterate_feature_rotations(df_All, 'Butanol')\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "flattened_results = []\n",
        "for ordered_features, importances in results:\n",
        "    for feature, importance in importances.items():\n",
        "        flattened_results.append({\n",
        "            'Feature Rotation': ordered_features,\n",
        "            'Feature': feature,\n",
        "            'Importance': importance\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(flattened_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                        Feature Rotation     Feature  \\\n",
            "0      [425_pct_Al, LC55557, FFC55553, FC55003, PI550...  425_pct_Al   \n",
            "1      [425_pct_Al, LC55557, FFC55553, FC55003, PI550...     LC55557   \n",
            "2      [425_pct_Al, LC55557, FFC55553, FC55003, PI550...    FFC55553   \n",
            "3      [425_pct_Al, LC55557, FFC55553, FC55003, PI550...     FC55003   \n",
            "4      [425_pct_Al, LC55557, FFC55553, FC55003, PI550...     PI55004   \n",
            "...                                                  ...         ...   \n",
            "26995  [TI55021, M_Value, DI55102, 425_pct_Al, FC5557...     PI55004   \n",
            "26996  [TI55021, M_Value, DI55102, 425_pct_Al, FC5557...     DI55580   \n",
            "26997  [TI55021, M_Value, DI55102, 425_pct_Al, FC5557...  C4_pct_Hex   \n",
            "26998  [TI55021, M_Value, DI55102, 425_pct_Al, FC5557...     LC90366   \n",
            "26999  [TI55021, M_Value, DI55102, 425_pct_Al, FC5557...     TC55553   \n",
            "\n",
            "       Importance  \n",
            "0           497.0  \n",
            "1           284.0  \n",
            "2           217.0  \n",
            "3           226.0  \n",
            "4           174.0  \n",
            "...           ...  \n",
            "26995       117.0  \n",
            "26996       129.0  \n",
            "26997       157.0  \n",
            "26998       150.0  \n",
            "26999       119.0  \n",
            "\n",
            "[27000 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Group by 'Feature' and calculate the average importance\n",
        "average_importances = results_df.groupby('Feature')['Importance'].mean()\n",
        "\n",
        "# Convert the Series to a DataFrame\n",
        "average_importances_df = average_importances.reset_index()\n",
        "\n",
        "# Rename the columns for clarity\n",
        "average_importances_df.columns = ['Feature', 'Average Importance']\n",
        "\n",
        "# Sort the DataFrame by 'Average Importance' in descending order\n",
        "average_importances_df = average_importances_df.sort_values(by='Average Importance', ascending=False)\n",
        "\n",
        "# # Display or save the DataFrame\n",
        "# print(average_importances_df)\n",
        "# # Or save it to a CSV file\n",
        "# # average_importances_df.to_csv('average_feature_importances.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               Feature  Average Importance                Description\n",
            "0          HydWtr_Na2O          223.136667                        NaN\n",
            "1   HydWtr_pct_Ammonia          215.513333                        NaN\n",
            "2           425_pct_Al          208.247778                        NaN\n",
            "3              FC55569          199.868889     30# STM TO C4 STRIPPER\n",
            "4           C4_pct_H2O          193.913333                        NaN\n",
            "5              LC55557          193.154444        FA-554 SLURRY LEVEL\n",
            "6              TC55552          192.710000   DC-551 ALKOX  FD PREHEAT\n",
            "7           C4_pct_Hex          189.655556                        NaN\n",
            "8              DI55102          186.996667           HYDROL RX OUTLET\n",
            "9              FC55552          184.591111   ALK FD TO HYDR RX DC-551\n",
            "10          C4_pct_Eth          184.134444                        NaN\n",
            "11             FC55003          182.184444   DA-551 O/H H2O TO DC-551\n",
            "12             FC55576          180.901111   CONDENSATE TO DESUPERHTR\n",
            "13             LC90368          178.823333       FB-658 ALKOXIDE TANK\n",
            "14             TC55555          175.145556        EA-552 OUT  RECY C4\n",
            "15             LC90366          174.923333         FB-657 SAO STORAGE\n",
            "16             DI55152          173.316667     2ND STG SEPR TO FA-560\n",
            "17             LC55553          171.636667   DC551 HYDR RX SLURRY LEV\n",
            "18            FFC55555          170.332222   RECYC BUT/ALKOX FD RATIO\n",
            "19            FFC55553          163.464444   DC551 H2O/ALKOXIDE RATIO\n",
            "20               Al2O3          162.303333                        NaN\n",
            "21             M_Value          161.100000                        NaN\n",
            "22             LC52572          158.661111   FB-554 SLURRY SURGE TANK\n",
            "23             TC55553          152.581111    DC-551 HYDR H2O PREHEAT\n",
            "24             DI55580          152.202222   DA-554 BTMS SLURRY TO EX\n",
            "25             PI55004          145.938889     DA-554 BOTTOM PRESSURE\n",
            "26             TI55021          143.554444             STEAM TO DA554\n",
            "27             LC55568          143.480000    DA-554 C4 STRPR BOTTOMS\n",
            "28             TI40050          141.392222  CLARK AIR COMP INLET TEMP\n",
            "29             PI55020          129.136667        DA-554 TOP PRESSURE\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\austinsh\\AppData\\Local\\Temp\\ipykernel_18976\\3091506829.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  final_df.rename(columns={'DESCRIPTION': 'Description'}, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# Merge the average_importances_df with df_TagDesc\n",
        "# Assuming 'ID' in df_TagDesc corresponds to 'Feature' in average_importances_df\n",
        "merged_df = average_importances_df.merge(df_TagDesc, left_on='Feature', right_on='ID', how='left')\n",
        "\n",
        "# Select only the required columns\n",
        "final_df = merged_df[['Feature', 'Average Importance', 'DESCRIPTION']]\n",
        "\n",
        "# Rename the 'DESCRIPTION' column to 'Description'\n",
        "final_df.rename(columns={'DESCRIPTION': 'Description'}, inplace=True)\n",
        "\n",
        "# Display or save the DataFrame\n",
        "print(final_df)\n",
        "# Or save it to a CSV file\n",
        "# final_df.to_csv('average_feature_importances_with_descriptions.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-05-06 21:14:57.027830\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Get the current date and time\n",
        "current_date_time = datetime.now()\n",
        "\n",
        "# Print the current date and time\n",
        "print(current_date_time)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
