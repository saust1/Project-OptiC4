{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\austinsh\\AppData\\Local\\Temp\\ipykernel_23800\\1304120184.py:1: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Set max columns to display\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import preprocessing as pre\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Importing CSV files\n",
        "# df_CDunit = pd.read_csv('https://raw.githubusercontent.com/saust1/Project-OptiC4/main/1%20Preprocess/Continuous%20Data/cont_554Data_clean.csv')\n",
        "# df_AlCon = pd.read_csv('https://raw.githubusercontent.com/saust1/Project-OptiC4/main/1%20Preprocess/Continuous%20Data/cont_425Data_clean.csv')\n",
        "# df_FB554 = pd.read_csv('https://raw.githubusercontent.com/saust1/Project-OptiC4/main/1%20Preprocess/Continuous%20Data/cont_unitData_clean.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Importing CSV files\n",
        "# bordeCode directory\n",
        "df_CDunit = pd.read_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\IV Optimize\\Continuous Data\\cont_unitData_clean.csv')\n",
        "df_AlCon = pd.read_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\IV Optimize\\Continuous Data\\cont_425Data_clean.csv')\n",
        "df_FB554 = pd.read_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\IV Optimize\\Continuous Data\\cont_554Data_clean.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            DI55102       DI55152       FC55003       FC55552       FC55569  \\\n",
            "count  48806.000000  48806.000000  48806.000000  48806.000000  48806.000000   \n",
            "mean       0.944831      0.933324   5995.076190  36160.195195   6608.439755   \n",
            "std        0.052697      0.029800    851.268879   4676.181585    381.543221   \n",
            "min        0.800007      0.837341   2861.120000  18205.900000   5147.960000   \n",
            "25%        0.910894      0.913208   5483.547500  35010.300000   6379.075000   \n",
            "50%        0.950356      0.933329   6015.470000  37970.900000   6584.330000   \n",
            "75%        0.984626      0.952618   6556.990000  39030.775000   6818.920000   \n",
            "max        1.061510      1.025180   9134.330000  52000.000000   8100.740000   \n",
            "\n",
            "            FC55576      FFC55555       LC55557       LC90366       LC90368  \\\n",
            "count  48806.000000  48806.000000  48806.000000  48806.000000  48806.000000   \n",
            "mean     368.052255      0.772328     69.428048     46.226414     36.669846   \n",
            "std      256.912595      0.022550      2.874277     29.036939     20.023552   \n",
            "min        0.000000      0.690043     60.147100      0.000000      0.006367   \n",
            "25%      187.294000      0.758764     66.907750     20.967025     20.683300   \n",
            "50%      338.340000      0.774042     70.064500     47.586250     41.774450   \n",
            "75%      545.391250      0.788200     71.645550     76.996200     51.716075   \n",
            "max     1132.440000      0.852451     78.662700     87.901600     81.210800   \n",
            "\n",
            "            TC55552  \n",
            "count  48806.000000  \n",
            "mean     168.885972  \n",
            "std       15.367959  \n",
            "min      120.095000  \n",
            "25%      155.630000  \n",
            "50%      172.875000  \n",
            "75%      181.074000  \n",
            "max      202.625000  \n",
            "         425_pct_Al    C4_pct_Eth    C4_pct_H2O  HydWtr_pct_Ammonia  \\\n",
            "count  48806.000000  48806.000000  48806.000000        48806.000000   \n",
            "mean       6.146661      1.231848     21.202520            0.968714   \n",
            "std        0.257063      0.723519      2.743841            0.151169   \n",
            "min        5.172450      0.085999      8.012620            0.350000   \n",
            "25%        6.005892      0.628879     18.858000            0.876385   \n",
            "50%        6.140625      1.104860     21.463750            0.940263   \n",
            "75%        6.288605      1.696108     23.334350            1.031440   \n",
            "max        7.138780      9.844330     34.783400            1.629800   \n",
            "\n",
            "        HydWtr_Na2O  \n",
            "count  48806.000000  \n",
            "mean       0.811433  \n",
            "std        0.702541  \n",
            "min        0.000000  \n",
            "25%        0.455526  \n",
            "50%        0.665238  \n",
            "75%        0.984490  \n",
            "max       13.026300  \n",
            "            Butanol\n",
            "count  48806.000000\n",
            "mean       9.941539\n",
            "std       10.284052\n",
            "min        0.000000\n",
            "25%        3.893330\n",
            "50%        5.966670\n",
            "75%       11.084250\n",
            "max       58.645000\n"
          ]
        }
      ],
      "source": [
        "print(df_CDunit.describe())\n",
        "print(df_AlCon.describe())\n",
        "print(df_FB554.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data type for 'Date' column in df_CDunit: object\n",
            "Data type for 'Date' column in df_FB554: object\n",
            "Data type for 'Date' column in df_AlCon: object\n"
          ]
        }
      ],
      "source": [
        "print(\"Data type for 'Date' column in df_CDunit:\", df_CDunit['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_FB554:\", df_FB554['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_AlCon:\", df_AlCon['Date'].dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_CDunit['Date'] = pd.to_datetime(df_CDunit['Date'], errors='coerce')\n",
        "df_FB554['Date'] = pd.to_datetime(df_FB554['Date'], errors='coerce')\n",
        "df_AlCon['Date'] = pd.to_datetime(df_AlCon['Date'], errors='coerce')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data type for 'Date' column in df_CDunit: datetime64[ns]\n",
            "Data type for 'Date' column in df_FB554: datetime64[ns]\n",
            "Data type for 'Date' column in df_AlCon: datetime64[ns]\n"
          ]
        }
      ],
      "source": [
        "print(\"Data type for 'Date' column in df_CDunit:\", df_CDunit['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_FB554:\", df_FB554['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_AlCon:\", df_AlCon['Date'].dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Date', 'DI55102', 'DI55152', 'FC55003', 'FC55552', 'FC55569',\n",
            "       'FC55576', 'FFC55555', 'LC55557', 'LC90366', 'LC90368', 'TC55552'],\n",
            "      dtype='object')\n",
            "Index(['Date', 'Butanol'], dtype='object')\n",
            "Index(['Date', '425_pct_Al', 'C4_pct_Eth', 'C4_pct_H2O', 'HydWtr_pct_Ammonia',\n",
            "       'HydWtr_Na2O'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df_CDunit.columns)\n",
        "print(df_FB554.columns)\n",
        "print(df_AlCon.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_rolling_average_to_df(df, rolling_size):\n",
        "    # Ensure 'Date' is the index if it's not already\n",
        "    if df.index.name != 'Date':\n",
        "        df = df.set_index('Date')\n",
        "\n",
        "    # Apply rolling average to all columns\n",
        "    rolled_df = df.rolling(window=rolling_size, min_periods=1).mean()\n",
        "\n",
        "    # Reset index to make 'Date' a column again\n",
        "    rolled_df = rolled_df.reset_index()\n",
        "\n",
        "    return rolled_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_time_shift_by_hours(df, shift_hours):\n",
        "    \"\"\"\n",
        "    Shifts the DataFrame's datetime index by the specified number of hours.\n",
        "\n",
        "    :param df: DataFrame with 'Date' as its datetime index or column.\n",
        "    :param shift_hours: Number of hours to shift. Can be positive (forward) or negative (backward).\n",
        "    :return: Shifted DataFrame.\n",
        "    \"\"\"\n",
        "    # Convert 'Date' to datetime and set as index if it's not already\n",
        "    if df.index.name != 'Date':\n",
        "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "        df = df.set_index('Date')\n",
        "\n",
        "    # Ensure the index is a DatetimeIndex\n",
        "    df.index = pd.to_datetime(df.index)\n",
        "\n",
        "    # Shift the DataFrame's index by the specified number of hours\n",
        "    df.index = df.index + pd.Timedelta(hours=shift_hours)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Usage Examples\n",
        "# shift_hours_AlCon = 1  # Negative shift for df_AlCon (e.g., -5 hours backward)\n",
        "# shift_hours_FB554 = 5   # Positive shift for df_FB554 (e.g., 5 hours forward)\n",
        "\n",
        "# shifted_df_AlCon = apply_time_shift_by_hours(df_AlCon, shift_hours_AlCon)\n",
        "# print(\"Shifted df_AlCon:\")\n",
        "# print(shifted_df_AlCon.head())\n",
        "\n",
        "# shifted_df_FB554 = apply_time_shift_by_hours(df_FB554, shift_hours_FB554)\n",
        "# print(\"\\nShifted df_FB554:\")\n",
        "# print(shifted_df_FB554.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def join_df_FB554_to_df_CDunit(df_CDunit, df_FB554):\n",
        "    # Reset index if 'Date' is the index\n",
        "    if df_CDunit.index.name == 'Date':\n",
        "        df_CDunit = df_CDunit.reset_index()\n",
        "    if df_FB554.index.name == 'Date':\n",
        "        df_FB554 = df_FB554.reset_index()\n",
        "\n",
        "    # Ensure 'Date' columns are datetime objects and sort DataFrames\n",
        "    df_CDunit['Date'] = pd.to_datetime(df_CDunit['Date'], errors='coerce')\n",
        "    df_FB554['Date'] = pd.to_datetime(df_FB554['Date'], errors='coerce')\n",
        "\n",
        "    df_CDunit = df_CDunit.dropna(subset=['Date']).sort_values('Date')\n",
        "    df_FB554 = df_FB554.dropna(subset=['Date']).sort_values('Date')\n",
        "\n",
        "    # Perform merge_asof\n",
        "    combined_df = pd.merge_asof(df_FB554, df_CDunit, on='Date', direction='nearest')\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "def join_df_AlCon_to_combined_df(combined_df, df_AlCon):\n",
        "    # Reset index if 'Date' is the index\n",
        "    if combined_df.index.name == 'Date':\n",
        "        combined_df = combined_df.reset_index()\n",
        "    if df_AlCon.index.name == 'Date':\n",
        "        df_AlCon = df_AlCon.reset_index()\n",
        "\n",
        "    # Ensure 'Date' columns are datetime objects and sort DataFrames\n",
        "    combined_df['Date'] = pd.to_datetime(combined_df['Date'], errors='coerce')\n",
        "    df_AlCon['Date'] = pd.to_datetime(df_AlCon['Date'], errors='coerce')\n",
        "\n",
        "    combined_df = combined_df.dropna(subset=['Date']).sort_values('Date')\n",
        "    df_AlCon = df_AlCon.dropna(subset=['Date']).sort_values('Date')\n",
        "\n",
        "    # Perform merge_asof\n",
        "    combined_df_all = pd.merge_asof(df_AlCon, combined_df, on='Date', direction='nearest')\n",
        "    \n",
        "    return combined_df_all\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data type for 'Date' column in df_CDunit: datetime64[ns]\n",
            "Data type for 'Date' column in df_FB554: datetime64[ns]\n",
            "Data type for 'Date' column in df_AlCon: datetime64[ns]\n"
          ]
        }
      ],
      "source": [
        "print(\"Data type for 'Date' column in df_CDunit:\", df_CDunit['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_FB554:\", df_FB554['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_AlCon:\", df_AlCon['Date'].dtypes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_data_limited():\n",
        "    # Apply the specific rolling average directly\n",
        "    rolled_df_CDunit = apply_rolling_average_to_df(df_CDunit, 8)\n",
        "    rolled_df_FB554 = apply_rolling_average_to_df(df_FB554, 4)\n",
        "    rolled_df_AlCon = apply_rolling_average_to_df(df_AlCon, 2)\n",
        "\n",
        "    # Apply the specific time shifts directly\n",
        "    rolled_df_AlCon_shifted = apply_time_shift_by_hours(rolled_df_AlCon, -1) # Assuming apply_time_shift_by_hours handles negative shifts correctly\n",
        "    rolled_df_FB554_shifted = apply_time_shift_by_hours(rolled_df_FB554, 1)\n",
        "\n",
        "    # Combine df_CDunit and df_FB554 to create combined_df\n",
        "    combined_df = join_df_FB554_to_df_CDunit(rolled_df_CDunit, rolled_df_FB554_shifted)\n",
        "\n",
        "    # Combine combined_df with rolled_df_AlCon to create combined_df_all\n",
        "    combined_df_all = join_df_AlCon_to_combined_df(combined_df, rolled_df_AlCon_shifted)\n",
        "\n",
        "    # At this point, combined_df_all is the DataFrame with the data processed by the specified shifts and averages\n",
        "    return combined_df_all\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 Date  425_pct_Al  C4_pct_Eth  C4_pct_H2O  HydWtr_pct_Ammonia  \\\n",
            "0 2012-05-16 15:00:00    6.306930    2.505710    21.95810            0.909887   \n",
            "1 2012-05-16 16:00:00    6.307280    2.507065    21.96075            0.909326   \n",
            "2 2012-05-16 18:00:00    6.308335    2.511135    21.96865            0.907643   \n",
            "3 2012-05-16 19:00:00    6.309390    2.515210    21.97655            0.905959   \n",
            "4 2012-05-16 20:00:00    6.310090    2.517925    21.98185            0.904837   \n",
            "\n",
            "   HydWtr_Na2O    Butanol   DI55102   DI55152    FC55003   FC55552   FC55569  \\\n",
            "0     2.618940  58.526500  0.970151  0.924718  4968.4400  41476.45  6915.395   \n",
            "1     2.665560  58.526500  0.970151  0.924718  4968.4400  41476.45  6915.395   \n",
            "2     2.805415  56.692400  0.970151  0.924718  4968.4400  41476.45  6915.395   \n",
            "3     2.945270  56.692400  0.970151  0.924718  4968.4400  41476.45  6915.395   \n",
            "4     3.038505  53.635533  0.970441  0.923875  5205.8625  41490.25  6915.535   \n",
            "\n",
            "     FC55576  FFC55555    LC55557    LC90366   LC90368    TC55552  \n",
            "0  338.08450  0.751216  65.844650  62.291900  51.34935  177.18800  \n",
            "1  338.08450  0.751216  65.844650  62.291900  51.34935  177.18800  \n",
            "2  338.08450  0.751216  65.844650  62.291900  51.34935  177.18800  \n",
            "3  338.08450  0.751216  65.844650  62.291900  51.34935  177.18800  \n",
            "4  334.65925  0.750611  65.922175  58.413975  51.01720  177.35975  \n"
          ]
        }
      ],
      "source": [
        "# Make sure all your helper functions and initial DataFrames (df_CDunit, df_FB554, df_AlCon) are correctly defined\n",
        "\n",
        "# Now, call the modified process_data function to get the processed DataFrame\n",
        "final_dataset = process_data_limited()\n",
        "\n",
        "# Inspect the final_dataset\n",
        "print(final_dataset.head())  # Print the first few rows to inspect the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save DataFrame to CSV file in the same directory as the Jupyter Notebook\n",
        "# model_results.to_csv('merged_data'.csv', index=False)\n",
        "                     \n",
        "# Save DataFrame to CSV file in the same directory as the Jupyter Notebook\n",
        "# df_CD.to_csv(r'C:\\Users\\steve\\OneDrive\\1. BAIUTEK\\Project-OptiC4\\1 Preprocess\\Continuous Data\\contData_all.csv', index=False)            \n",
        "\n",
        "final_dataset.to_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\IV Optimize\\Merge Data\\merged_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-22 01:18:11.254049\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Get the current date and time\n",
        "current_date_time = datetime.now()\n",
        "\n",
        "# Print the current date and time\n",
        "print(current_date_time)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
