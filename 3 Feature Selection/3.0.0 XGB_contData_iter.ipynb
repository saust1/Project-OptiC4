{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: statsmodels in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.18 in /home/codespace/.local/lib/python3.10/site-packages (from statsmodels) (1.26.2)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /home/codespace/.local/lib/python3.10/site-packages (from statsmodels) (1.11.3)\n",
            "Requirement already satisfied: pandas>=1.0 in /home/codespace/.local/lib/python3.10/site-packages (from statsmodels) (2.1.3)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from statsmodels) (0.5.4)\n",
            "Requirement already satisfied: packaging>=21.3 in /home/codespace/.local/lib/python3.10/site-packages (from statsmodels) (23.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0->statsmodels) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0->statsmodels) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=1.0->statsmodels) (2023.3)\n",
            "Requirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: mlxtend in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.23.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /home/codespace/.local/lib/python3.10/site-packages (from mlxtend) (1.11.3)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /home/codespace/.local/lib/python3.10/site-packages (from mlxtend) (1.26.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /home/codespace/.local/lib/python3.10/site-packages (from mlxtend) (2.1.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /home/codespace/.local/lib/python3.10/site-packages (from mlxtend) (1.3.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from mlxtend) (3.8.1)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /home/codespace/.local/lib/python3.10/site-packages (from mlxtend) (1.3.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (23.2)\n",
            "Requirement already satisfied: pillow>=8 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (10.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=0.24.2->mlxtend) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn>=1.0.2->mlxtend) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: xgboost in /usr/local/python/3.10.13/lib/python3.10/site-packages (2.0.2)\n",
            "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from xgboost) (1.26.2)\n",
            "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (from xgboost) (1.11.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install statsmodels\n",
        "%pip install mlxtend\n",
        "%pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.formula.api import ols\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import random\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df_All = pd.read_csv(r\"C:\\Users\\saust\\OneDrive - Sasol\\1 Project rC4\\Jupyter Notebooks\\Report 10-20-23 No Fluff\\df_All_Avg.csv\")\n",
        "\n",
        "df_All_1o2 = pd.read_csv('3 Feature Selection/contData_all_Avg - 1o2.csv')\n",
        "df_All_1o2 = pd.read_csv('3 Feature Selection/contData_all_Avg - 2o2.csv')\n",
        "\n",
        "#df_All = pd.read_csv(r\"C:\\Users\\saust\\OneDrive\\Desktop\\CodeSpace DLs\\102423\\Project rC4\\3 Final Machine Butanol\\df_CDCA6.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    425 %Al  Butanol   Decanol    Ethanol   Hexanol   Octanol  AYC55580  \\\n",
            "0  6.466835    8.950  3.271667  29.233325  5.862082  5.912500  9.708929   \n",
            "1  6.479165    8.750  3.261668  29.233325  5.832917  5.870832  9.647859   \n",
            "2  6.491500    8.525  3.310000  28.950000  5.767500  5.790000  9.592980   \n",
            "3  6.503835    8.275  3.416667  28.383325  5.665832  5.670000  9.572995   \n",
            "4  6.516165    8.025  3.523332  27.816675  5.564167  5.550000  9.586615   \n",
            "\n",
            "    DI55102   DI55152   DI55580  ...    TI40050     TI52014     TI55013  \\\n",
            "0  1.016935  0.974092  0.991364  ...  74.705737  134.922750  204.003375   \n",
            "1  1.017048  0.973535  0.991012  ...  74.042025  134.517750  203.384625   \n",
            "2  1.017505  0.973474  0.990783  ...  73.626350  134.084875  202.217250   \n",
            "3  1.017742  0.974004  0.990838  ...  73.203325  133.625625  201.412625   \n",
            "4  1.017679  0.974445  0.991013  ...  72.900725  133.217250  201.149500   \n",
            "\n",
            "      TI55014     TI55015     TI55016     TI55017     TI55021     TI55023  \\\n",
            "0  197.780625  193.192500  190.510125  188.871625  216.306750  213.595750   \n",
            "1  197.444250  192.960750  190.375875  188.838375  216.041375  213.364500   \n",
            "2  196.611375  192.210250  189.874750  188.452250  215.747250  213.030000   \n",
            "3  195.868875  191.353125  189.309125  187.879500  215.486500  212.716750   \n",
            "4  195.536625  190.952000  188.985875  187.550375  215.377250  212.599375   \n",
            "\n",
            "   VI52558B  \n",
            "0  3.970054  \n",
            "1  4.009966  \n",
            "2  4.011081  \n",
            "3  3.979564  \n",
            "4  3.901986  \n",
            "\n",
            "[5 rows x 49 columns]\n"
          ]
        }
      ],
      "source": [
        "# Concatenate (union) the dataframes\n",
        "df_All = pd.concat([df_All_1o2, df_All_1o2], ignore_index=True)\n",
        "\n",
        "print(df_All.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Set max columns to display\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_All = df_All[df_All['Date'] > '2022-06-15 00:00:00']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of columns to exclude to run XGboost feature selection\n",
        "exclude_columns = ['Octanol', 'Hexanol',\n",
        "       'Ethanol', 'Decanol',\n",
        "       \n",
        "       'TI52014', 'TI55013', 'TI55014', 'TI55015', 'TI55016', 'TI55017', 'TI55021', 'TI55023',\n",
        "       'TC52015', 'FC52018', 'II52554', 'TI40050', 'VI52558B'\n",
        "\n",
        "       # 'FC55102', 'FC55152', 'LC55557', 'LC55568', 'TC55555',\n",
        "\n",
        "       # '425 SAO Al', 'FFC55553', 'LC52572', 'LC90366',\n",
        "\n",
        "       # 'FC42428', 'LC55553',\n",
        "\n",
        "       # 'FC55009'\n",
        "                   ]\n",
        "\n",
        "# Create a new DataFrame without the excluded columnsd\n",
        "df_All = df_All.drop(columns=exclude_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['425 %Al', 'Butanol', 'AYC55580', 'DI55102', 'DI55152', 'DI55580',\n",
              "       'FC42428', 'FC55003', 'FC55009', 'FC55102', 'FC55152', 'FC55552',\n",
              "       'FC55555', 'FC55569', 'FC55576', 'FFC55553', 'FFC55555', 'FYC55553',\n",
              "       'LC52572', 'LC55553', 'LC55555', 'LC55557', 'LC55568', 'LC90366',\n",
              "       'LC90368', 'PI55004', 'PI55020', 'PI55560', 'TC55552', 'TC55553',\n",
              "       'TC55555', 'TC55566'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_All.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Splitting into train and test\n",
        "# X = df_All.drop('Butanol', axis=1)  # Assuming 'target' is your target column\n",
        "# y = df_All['Butanol']\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "def iterate_feature_rotations(df_all, target_column, test_size=0.2, random_state=42):\n",
        "    results = []\n",
        "    columns = [col for col in df_all.columns if col != target_column]\n",
        "    random.seed(random_state)  # for reproducibility\n",
        "\n",
        "    for feature in columns:\n",
        "        # Randomly order the remaining features\n",
        "        remaining_features = [f for f in columns if f != feature]\n",
        "        random.shuffle(remaining_features)\n",
        "\n",
        "        # Create a new ordered list of features\n",
        "        ordered_features = [feature] + remaining_features\n",
        "\n",
        "        reordered_df = df_all[ordered_features + [target_column]]\n",
        "\n",
        "        # Splitting into train and test for each permutation\n",
        "        X = reordered_df.drop(target_column, axis=1)\n",
        "        y = reordered_df[target_column]\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "        # Create and fit the XGBoost model\n",
        "        model = xgb.XGBRegressor(objective='reg:squarederror')\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Extract feature importances\n",
        "        feature_importances = model.get_booster().get_score(importance_type=\"weight\")\n",
        "\n",
        "        # Store the result with the permutation order and feature importances\n",
        "        results.append((ordered_features, feature_importances))\n",
        "\n",
        "    return results\n",
        "\n",
        "results = iterate_feature_rotations(df_All, 'Butanol')\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "flattened_results = []\n",
        "for ordered_features, importances in results:\n",
        "    for feature, importance in importances.items():\n",
        "        flattened_results.append({\n",
        "            'Feature Rotation': ordered_features,\n",
        "            'Feature': feature,\n",
        "            'Importance': importance\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(flattened_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                      Feature Rotation   Feature  Importance\n",
            "0    [425 %Al, LC55557, FFC55555, FC55555, TC55552,...   425 %Al       544.0\n",
            "1    [425 %Al, LC55557, FFC55555, FC55555, TC55552,...   LC55557       271.0\n",
            "2    [425 %Al, LC55557, FFC55555, FC55555, TC55552,...  FFC55555       190.0\n",
            "3    [425 %Al, LC55557, FFC55555, FC55555, TC55552,...   FC55555       182.0\n",
            "4    [425 %Al, LC55557, FFC55555, FC55555, TC55552,...   TC55552       237.0\n",
            "..                                                 ...       ...         ...\n",
            "956  [TC55566, TC55552, FC55552, FC55555, PI55004, ...   DI55580        64.0\n",
            "957  [TC55566, TC55552, FC55552, FC55555, PI55004, ...   LC52572       123.0\n",
            "958  [TC55566, TC55552, FC55552, FC55555, PI55004, ...   LC90366       154.0\n",
            "959  [TC55566, TC55552, FC55552, FC55555, PI55004, ...   425 %Al       184.0\n",
            "960  [TC55566, TC55552, FC55552, FC55555, PI55004, ...   FC55152        86.0\n",
            "\n",
            "[961 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Export the DataFrame to a CSV file\n",
        "results_df.to_csv('3 Feature Selection/feature_rotation_results.csv', index=False)\n",
        "\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def iterate_feature_rotations(df_all, target_column, test_size=0.2, random_state=42, num_random_iterations=30):\n",
        "    results = []\n",
        "    columns = [col for col in df_all.columns if col != target_column]\n",
        "    random.seed(random_state)  # for reproducibility\n",
        "\n",
        "    for feature in columns:\n",
        "        for _ in range(num_random_iterations):\n",
        "            # Randomly order the remaining features\n",
        "            remaining_features = [f for f in columns if f != feature]\n",
        "            random.shuffle(remaining_features)\n",
        "\n",
        "            # Create a new ordered list of features\n",
        "            ordered_features = [feature] + remaining_features\n",
        "\n",
        "            reordered_df = df_all[ordered_features + [target_column]]\n",
        "\n",
        "            # Splitting into train and test for each permutation\n",
        "            X = reordered_df.drop(target_column, axis=1)\n",
        "            y = reordered_df[target_column]\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "            # Create and fit the XGBoost model\n",
        "            model = xgb.XGBRegressor(objective='reg:squarederror')\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Extract feature importances\n",
        "            feature_importances = model.get_booster().get_score(importance_type=\"weight\")\n",
        "\n",
        "            # Store the result with the permutation order and feature importances\n",
        "            results.append((ordered_features, feature_importances))\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "results = iterate_feature_rotations(df_All, 'Butanol')\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "flattened_results = []\n",
        "for ordered_features, importances in results:\n",
        "    for feature, importance in importances.items():\n",
        "        flattened_results.append({\n",
        "            'Feature Rotation': ordered_features,\n",
        "            'Feature': feature,\n",
        "            'Importance': importance\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(flattened_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                        Feature Rotation   Feature  Importance\n",
            "0      [425 %Al, LC55557, FFC55555, FC55555, TC55552,...   425 %Al       544.0\n",
            "1      [425 %Al, LC55557, FFC55555, FC55555, TC55552,...   LC55557       271.0\n",
            "2      [425 %Al, LC55557, FFC55555, FC55555, TC55552,...  FFC55555       190.0\n",
            "3      [425 %Al, LC55557, FFC55555, FC55555, TC55552,...   FC55555       182.0\n",
            "4      [425 %Al, LC55557, FFC55555, FC55555, TC55552,...   TC55552       237.0\n",
            "...                                                  ...       ...         ...\n",
            "28825  [TC55566, TC55553, FC55102, FC55152, PI55560, ...   LC55568       135.0\n",
            "28826  [TC55566, TC55553, FC55102, FC55152, PI55560, ...  FFC55553       151.0\n",
            "28827  [TC55566, TC55553, FC55102, FC55152, PI55560, ...   PI55020       141.0\n",
            "28828  [TC55566, TC55553, FC55102, FC55152, PI55560, ...   FC55569       165.0\n",
            "28829  [TC55566, TC55553, FC55102, FC55152, PI55560, ...   425 %Al       183.0\n",
            "\n",
            "[28830 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Feature  Average Importance\n",
            "0    425 %Al          223.325806\n",
            "27   TC55552          208.392473\n",
            "6    FC55003          205.378495\n",
            "12   FC55569          200.308602\n",
            "22   LC90366          184.876344\n",
            "13   FC55576          184.584946\n",
            "14  FFC55553          180.894624\n",
            "25   PI55020          174.434409\n",
            "2    DI55102          171.945161\n",
            "21   LC55568          165.893548\n",
            "18   LC55553          164.563441\n",
            "29   TC55555          164.163441\n",
            "5    FC42428          163.369892\n",
            "30   TC55566          162.705376\n",
            "20   LC55557          159.604301\n",
            "7    FC55009          159.296774\n",
            "17   LC52572          158.851613\n",
            "28   TC55553          158.660215\n",
            "8    FC55102          158.011828\n",
            "23   LC90368          156.638710\n",
            "24   PI55004          154.949462\n",
            "3    DI55152          151.033333\n",
            "15  FFC55555          145.449462\n",
            "19   LC55555          136.402151\n",
            "11   FC55555          125.224731\n",
            "9    FC55152          120.858065\n",
            "26   PI55560          118.149462\n",
            "1   AYC55580          116.624731\n",
            "16  FYC55553          113.453763\n",
            "10   FC55552          107.283871\n",
            "4    DI55580          105.670968\n"
          ]
        }
      ],
      "source": [
        "# Group by 'Feature' and calculate the average importance\n",
        "average_importances = results_df.groupby('Feature')['Importance'].mean()\n",
        "\n",
        "# Convert the Series to a DataFrame\n",
        "average_importances_df = average_importances.reset_index()\n",
        "\n",
        "# Rename the columns for clarity\n",
        "average_importances_df.columns = ['Feature', 'Average Importance']\n",
        "\n",
        "# Sort the DataFrame by 'Average Importance' in descending order\n",
        "average_importances_df = average_importances_df.sort_values(by='Average Importance', ascending=False)\n",
        "\n",
        "# Display or save the DataFrame\n",
        "print(average_importances_df)\n",
        "# Or save it to a CSV file\n",
        "# average_importances_df.to_csv('average_feature_importances.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
