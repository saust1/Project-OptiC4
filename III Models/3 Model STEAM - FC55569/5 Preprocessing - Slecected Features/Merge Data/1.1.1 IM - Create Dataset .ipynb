{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\austinsh\\AppData\\Local\\Temp\\ipykernel_39036\\1304120184.py:1: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Set max columns to display\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import preprocessing as pre\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Importing CSV files\n",
        "# df_CDunit = pd.read_csv('https://raw.githubusercontent.com/saust1/Project-OptiC4/main/1%20Preprocess/Continuous%20Data/cont_554Data_clean.csv')\n",
        "# df_AlCon = pd.read_csv('https://raw.githubusercontent.com/saust1/Project-OptiC4/main/1%20Preprocess/Continuous%20Data/cont_425Data_clean.csv')\n",
        "# df_FB554 = pd.read_csv('https://raw.githubusercontent.com/saust1/Project-OptiC4/main/1%20Preprocess/Continuous%20Data/cont_unitData_clean.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Importing CSV files\n",
        "# bordeCode directory\n",
        "df_CDunit = pd.read_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\III Models\\3 Model STEAM - FC55569\\5 Preprocessing - Slecected Features\\Continuous Data\\cont_unitData_clean.csv')\n",
        "df_AlCon = pd.read_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\III Models\\3 Model STEAM - FC55569\\5 Preprocessing - Slecected Features\\Continuous Data\\cont_425Data_clean.csv')\n",
        "df_FB554 = pd.read_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\III Models\\3 Model STEAM - FC55569\\5 Preprocessing - Slecected Features\\Continuous Data\\cont_554Data_clean.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            DI55102       DI55152       DI55580       FC55003       FC55569  \\\n",
            "count  54561.000000  54561.000000  54561.000000  54561.000000  54561.000000   \n",
            "mean       0.943464      0.933740      0.999659   5997.874173   6619.660036   \n",
            "std        0.054314      0.030442      0.049659    929.965928    459.648371   \n",
            "min        0.800002      0.835069      0.848476    876.652000   3427.400000   \n",
            "25%        0.909271      0.913437      0.967906   5468.260000   6359.960000   \n",
            "50%        0.949199      0.933843      0.998969   6017.820000   6586.370000   \n",
            "75%        0.984290      0.953282      1.034240   6578.150000   6834.760000   \n",
            "max        1.062800      1.031740      1.144600  10609.000000  10171.500000   \n",
            "\n",
            "            FC55576      FFC55555       LC90366       PI55020       TI40050  \\\n",
            "count  54561.000000  54561.000000  54561.000000  54561.000000  54561.000000   \n",
            "mean     368.304281      0.772163     45.988848     -1.442503     73.095826   \n",
            "std      253.894618      0.024718     29.087032      1.147927     15.208337   \n",
            "min        0.000000      0.213109      0.000000     -5.012500     27.533700   \n",
            "25%      192.303000      0.758564     20.174500     -2.327720     62.597500   \n",
            "50%      342.637000      0.773306     47.182900     -1.421400     76.299800   \n",
            "75%      543.420000      0.788541     77.046100     -0.418453     84.557900   \n",
            "max     1132.440000      0.998409     87.901600      2.236610    118.700000   \n",
            "\n",
            "            TI55021  \n",
            "count  54561.000000  \n",
            "mean     223.764506  \n",
            "std       11.267038  \n",
            "min      150.495000  \n",
            "25%      217.452000  \n",
            "50%      220.366000  \n",
            "75%      224.428000  \n",
            "max      298.351000  \n",
            "         425_pct_Al         Al2O3    C4_pct_Eth    C4_pct_H2O    C4_pct_Hex\n",
            "count  54561.000000  54561.000000  54561.000000  54561.000000  54561.000000\n",
            "mean       6.156552     11.354136      1.252715     21.164006      0.458286\n",
            "std        0.274426      0.591839      0.799271      2.771817      0.237698\n",
            "min        4.815620      9.541520      0.009510      8.258290      0.000060\n",
            "25%        6.009700     11.069600      0.630762     18.797400      0.338534\n",
            "50%        6.148420     11.487300      1.134980     21.392100      0.437896\n",
            "75%        6.306480     11.715900      1.693370     23.305300      0.538039\n",
            "max        7.436160     12.880700     11.355000     34.605000      3.053900\n",
            "            Butanol\n",
            "count  54561.000000\n",
            "mean       9.873995\n",
            "std       10.573901\n",
            "min        0.000000\n",
            "25%        3.780000\n",
            "50%        5.833330\n",
            "75%       10.896700\n",
            "max       61.840000\n"
          ]
        }
      ],
      "source": [
        "print(df_CDunit.describe())\n",
        "print(df_AlCon.describe())\n",
        "print(df_FB554.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data type for 'Date' column in df_CDunit: object\n",
            "Data type for 'Date' column in df_FB554: object\n",
            "Data type for 'Date' column in df_AlCon: object\n"
          ]
        }
      ],
      "source": [
        "print(\"Data type for 'Date' column in df_CDunit:\", df_CDunit['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_FB554:\", df_FB554['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_AlCon:\", df_AlCon['Date'].dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_CDunit['Date'] = pd.to_datetime(df_CDunit['Date'], errors='coerce')\n",
        "df_FB554['Date'] = pd.to_datetime(df_FB554['Date'], errors='coerce')\n",
        "df_AlCon['Date'] = pd.to_datetime(df_AlCon['Date'], errors='coerce')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data type for 'Date' column in df_CDunit: datetime64[ns]\n",
            "Data type for 'Date' column in df_FB554: datetime64[ns]\n",
            "Data type for 'Date' column in df_AlCon: datetime64[ns]\n"
          ]
        }
      ],
      "source": [
        "print(\"Data type for 'Date' column in df_CDunit:\", df_CDunit['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_FB554:\", df_FB554['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_AlCon:\", df_AlCon['Date'].dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Date', 'DI55102', 'DI55152', 'DI55580', 'FC55003', 'FC55569',\n",
            "       'FC55576', 'FFC55555', 'LC90366', 'PI55020', 'TI40050', 'TI55021'],\n",
            "      dtype='object')\n",
            "Index(['Date', 'Butanol'], dtype='object')\n",
            "Index(['Date', '425_pct_Al', 'Al2O3', 'C4_pct_Eth', 'C4_pct_H2O',\n",
            "       'C4_pct_Hex'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df_CDunit.columns)\n",
        "print(df_FB554.columns)\n",
        "print(df_AlCon.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_rolling_average_to_df(df, rolling_size):\n",
        "    # Ensure 'Date' is the index if it's not already\n",
        "    if df.index.name != 'Date':\n",
        "        df = df.set_index('Date')\n",
        "\n",
        "    # Apply rolling average to all columns\n",
        "    rolled_df = df.rolling(window=rolling_size, min_periods=1).mean()\n",
        "\n",
        "    # Reset index to make 'Date' a column again\n",
        "    rolled_df = rolled_df.reset_index()\n",
        "\n",
        "    return rolled_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_time_shift_by_hours(df, shift_hours):\n",
        "    \"\"\"\n",
        "    Shifts the DataFrame's datetime index by the specified number of hours.\n",
        "\n",
        "    :param df: DataFrame with 'Date' as its datetime index or column.\n",
        "    :param shift_hours: Number of hours to shift. Can be positive (forward) or negative (backward).\n",
        "    :return: Shifted DataFrame.\n",
        "    \"\"\"\n",
        "    # Convert 'Date' to datetime and set as index if it's not already\n",
        "    if df.index.name != 'Date':\n",
        "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "        df = df.set_index('Date')\n",
        "\n",
        "    # Ensure the index is a DatetimeIndex\n",
        "    df.index = pd.to_datetime(df.index)\n",
        "\n",
        "    # Shift the DataFrame's index by the specified number of hours\n",
        "    df.index = df.index + pd.Timedelta(hours=shift_hours)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Usage Examples\n",
        "# shift_hours_AlCon = 1  # Negative shift for df_AlCon (e.g., -5 hours backward)\n",
        "# shift_hours_FB554 = 5   # Positive shift for df_FB554 (e.g., 5 hours forward)\n",
        "\n",
        "# shifted_df_AlCon = apply_time_shift_by_hours(df_AlCon, shift_hours_AlCon)\n",
        "# print(\"Shifted df_AlCon:\")\n",
        "# print(shifted_df_AlCon.head())\n",
        "\n",
        "# shifted_df_FB554 = apply_time_shift_by_hours(df_FB554, shift_hours_FB554)\n",
        "# print(\"\\nShifted df_FB554:\")\n",
        "# print(shifted_df_FB554.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def join_df_FB554_to_df_CDunit(df_CDunit, df_FB554):\n",
        "    # Reset index if 'Date' is the index\n",
        "    if df_CDunit.index.name == 'Date':\n",
        "        df_CDunit = df_CDunit.reset_index()\n",
        "    if df_FB554.index.name == 'Date':\n",
        "        df_FB554 = df_FB554.reset_index()\n",
        "\n",
        "    # Ensure 'Date' columns are datetime objects and sort DataFrames\n",
        "    df_CDunit['Date'] = pd.to_datetime(df_CDunit['Date'], errors='coerce')\n",
        "    df_FB554['Date'] = pd.to_datetime(df_FB554['Date'], errors='coerce')\n",
        "\n",
        "    df_CDunit = df_CDunit.dropna(subset=['Date']).sort_values('Date')\n",
        "    df_FB554 = df_FB554.dropna(subset=['Date']).sort_values('Date')\n",
        "\n",
        "    # Perform merge_asof\n",
        "    combined_df = pd.merge_asof(df_FB554, df_CDunit, on='Date', direction='nearest')\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "def join_df_AlCon_to_combined_df(combined_df, df_AlCon):\n",
        "    # Reset index if 'Date' is the index\n",
        "    if combined_df.index.name == 'Date':\n",
        "        combined_df = combined_df.reset_index()\n",
        "    if df_AlCon.index.name == 'Date':\n",
        "        df_AlCon = df_AlCon.reset_index()\n",
        "\n",
        "    # Ensure 'Date' columns are datetime objects and sort DataFrames\n",
        "    combined_df['Date'] = pd.to_datetime(combined_df['Date'], errors='coerce')\n",
        "    df_AlCon['Date'] = pd.to_datetime(df_AlCon['Date'], errors='coerce')\n",
        "\n",
        "    combined_df = combined_df.dropna(subset=['Date']).sort_values('Date')\n",
        "    df_AlCon = df_AlCon.dropna(subset=['Date']).sort_values('Date')\n",
        "\n",
        "    # Perform merge_asof\n",
        "    combined_df_all = pd.merge_asof(df_AlCon, combined_df, on='Date', direction='nearest')\n",
        "    \n",
        "    return combined_df_all\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data type for 'Date' column in df_CDunit: datetime64[ns]\n",
            "Data type for 'Date' column in df_FB554: datetime64[ns]\n",
            "Data type for 'Date' column in df_AlCon: datetime64[ns]\n"
          ]
        }
      ],
      "source": [
        "print(\"Data type for 'Date' column in df_CDunit:\", df_CDunit['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_FB554:\", df_FB554['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_AlCon:\", df_AlCon['Date'].dtypes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_data_limited():\n",
        "    # Apply the specific rolling average directly\n",
        "    rolled_df_CDunit = apply_rolling_average_to_df(df_CDunit, 8)\n",
        "    rolled_df_FB554 = apply_rolling_average_to_df(df_FB554, 4)\n",
        "    rolled_df_AlCon = apply_rolling_average_to_df(df_AlCon, 2)\n",
        "\n",
        "    # Apply the specific time shifts directly\n",
        "    rolled_df_AlCon_shifted = apply_time_shift_by_hours(rolled_df_AlCon, -1) # Assuming apply_time_shift_by_hours handles negative shifts correctly\n",
        "    rolled_df_FB554_shifted = apply_time_shift_by_hours(rolled_df_FB554, 1)\n",
        "\n",
        "    # Combine df_CDunit and df_FB554 to create combined_df\n",
        "    combined_df = join_df_FB554_to_df_CDunit(rolled_df_CDunit, rolled_df_FB554_shifted)\n",
        "\n",
        "    # Combine combined_df with rolled_df_AlCon to create combined_df_all\n",
        "    combined_df_all = join_df_AlCon_to_combined_df(combined_df, rolled_df_AlCon_shifted)\n",
        "\n",
        "    # At this point, combined_df_all is the DataFrame with the data processed by the specified shifts and averages\n",
        "    return combined_df_all\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 Date  425_pct_Al     Al2O3  C4_pct_Eth  C4_pct_H2O  \\\n",
            "0 2012-05-13 17:00:00    6.257800  11.85580    2.315660    21.58900   \n",
            "1 2012-05-13 18:00:00    6.258150  11.87625    2.317015    21.59160   \n",
            "2 2012-05-13 19:00:00    6.258850  11.91710    2.319730    21.59685   \n",
            "3 2012-05-13 20:00:00    6.259555  11.95790    2.322445    21.60215   \n",
            "4 2012-05-13 21:00:00    6.260260  11.99875    2.325160    21.60745   \n",
            "\n",
            "   C4_pct_Hex    Butanol   DI55102   DI55152   DI55580      FC55003  \\\n",
            "0    0.611370  57.958400  0.975939  0.949229  1.032360  6570.240000   \n",
            "1    0.611707  57.958400  0.975939  0.949229  1.032360  6570.240000   \n",
            "2    0.612382  57.958400  0.975939  0.949229  1.032360  6570.240000   \n",
            "3    0.613056  54.875500  0.975904  0.948656  1.032043  6634.436667   \n",
            "4    0.613730  51.792567  0.975875  0.948095  1.031655  6694.237500   \n",
            "\n",
            "       FC55569    FC55576  FFC55555  LC90366   PI55020    TI40050     TI55021  \n",
            "0  6465.030000  334.73200  0.748898  82.1746 -0.350805  83.248300  213.937000  \n",
            "1  6465.030000  334.73200  0.748898  82.1746 -0.350805  83.248300  213.937000  \n",
            "2  6465.030000  334.73200  0.748898  82.1746 -0.350805  83.248300  213.937000  \n",
            "3  6465.943333  336.82900  0.749250  82.1746 -0.413804  81.575367  213.706333  \n",
            "4  6466.167500  335.50075  0.749331  82.1746 -0.440142  80.006075  213.401250  \n"
          ]
        }
      ],
      "source": [
        "# Make sure all your helper functions and initial DataFrames (df_CDunit, df_FB554, df_AlCon) are correctly defined\n",
        "\n",
        "# Now, call the modified process_data function to get the processed DataFrame\n",
        "final_dataset = process_data_limited()\n",
        "\n",
        "# Inspect the final_dataset\n",
        "print(final_dataset.head())  # Print the first few rows to inspect the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Date', '425_pct_Al', 'Al2O3', 'C4_pct_Eth', 'C4_pct_H2O', 'C4_pct_Hex',\n",
              "       'Butanol', 'DI55102', 'DI55152', 'DI55580', 'FC55003', 'FC55569',\n",
              "       'FC55576', 'FFC55555', 'LC90366', 'PI55020', 'TI40050', 'TI55021'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_dataset.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save DataFrame to CSV file in the same directory as the Jupyter Notebook\n",
        "# model_results.to_csv('merged_data'.csv', index=False)\n",
        "                     \n",
        "# Save DataFrame to CSV file in the same directory as the Jupyter Notebook\n",
        "# df_CD.to_csv(r'C:\\Users\\steve\\OneDrive\\1. BAIUTEK\\Project-OptiC4\\1 Preprocess\\Continuous Data\\contData_all.csv', index=False)            \n",
        "\n",
        "final_dataset.to_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\III Models\\3 Model STEAM - FC55569\\5 Preprocessing - Slecected Features\\Merge Data\\merged_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-05-05 22:36:31.936015\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Get the current date and time\n",
        "current_date_time = datetime.now()\n",
        "\n",
        "# Print the current date and time\n",
        "print(current_date_time)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
