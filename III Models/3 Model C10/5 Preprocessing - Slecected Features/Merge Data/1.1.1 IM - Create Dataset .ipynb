{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\austinsh\\AppData\\Local\\Temp\\ipykernel_48612\\1304120184.py:1: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Set max columns to display\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import preprocessing as pre\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Importing CSV files\n",
        "# df_CDunit = pd.read_csv('https://raw.githubusercontent.com/saust1/Project-OptiC4/main/1%20Preprocess/Continuous%20Data/cont_554Data_clean.csv')\n",
        "# df_AlCon = pd.read_csv('https://raw.githubusercontent.com/saust1/Project-OptiC4/main/1%20Preprocess/Continuous%20Data/cont_425Data_clean.csv')\n",
        "# df_FB554 = pd.read_csv('https://raw.githubusercontent.com/saust1/Project-OptiC4/main/1%20Preprocess/Continuous%20Data/cont_unitData_clean.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Importing CSV files\n",
        "# bordeCode directory\n",
        "df_CDunit = pd.read_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\III Models\\3 Model C10\\5 Preprocessing - Slecected Features\\Continuous Data\\cont_unitData_clean.csv')\n",
        "df_AlCon = pd.read_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\III Models\\3 Model C10\\5 Preprocessing - Slecected Features\\Continuous Data\\cont_425Data_clean.csv')\n",
        "df_FB554 = pd.read_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\III Models\\3 Model C10\\5 Preprocessing - Slecected Features\\Continuous Data\\cont_554Data_clean.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            DI55102       DI55152       FC55003       FC55552       FC55569  \\\n",
            "count  51276.000000  51276.000000  51276.000000  51276.000000  51276.000000   \n",
            "mean       0.943637      0.933149   5996.438769  35905.715089   6607.317682   \n",
            "std        0.054174      0.030232    858.862368   5055.523287    395.939854   \n",
            "min        0.800002      0.837031   2823.920000  17996.100000   5135.670000   \n",
            "25%        0.909285      0.912829   5481.060000  34933.275000   6370.660000   \n",
            "50%        0.949218      0.933393   6014.140000  37960.000000   6584.415000   \n",
            "75%        0.984700      0.952681   6562.375000  39022.700000   6823.535000   \n",
            "max        1.061510      1.025180   9170.840000  52000.000000   8114.690000   \n",
            "\n",
            "            FC55576      FFC55555       LC55557       LC90366       LC90368  \\\n",
            "count  51276.000000  51276.000000  51276.000000  51276.000000  51276.000000   \n",
            "mean     367.354165      0.771989     69.454574     46.226400     36.433544   \n",
            "std      256.408521      0.023064      2.904752     28.943898     20.106838   \n",
            "min        0.000000      0.687883     60.061400      0.000000      0.006367   \n",
            "25%      186.503750      0.758508     66.945500     21.222600     19.991775   \n",
            "50%      339.382000      0.773440     70.081050     47.668800     41.422750   \n",
            "75%      547.502750      0.788222     71.726650     76.976300     51.743250   \n",
            "max     1132.440000      0.857842     78.662700     87.901600     81.210800   \n",
            "\n",
            "            TC55552  \n",
            "count  51276.000000  \n",
            "mean     168.789842  \n",
            "std       15.296005  \n",
            "min      119.840000  \n",
            "25%      155.687000  \n",
            "50%      172.694000  \n",
            "75%      180.884250  \n",
            "max      202.625000  \n",
            "         425_pct_Al    C4_pct_Eth    C4_pct_H2O  HydWtr_pct_Ammonia  \\\n",
            "count  51276.000000  51276.000000  51276.000000        51276.000000   \n",
            "mean       6.152577      1.231762     21.188189            0.970658   \n",
            "std        0.259811      0.729966      2.742453            0.154151   \n",
            "min        5.175720      0.009510      8.012620            0.350000   \n",
            "25%        6.008258      0.629523     18.833250            0.875801   \n",
            "50%        6.144140      1.113490     21.447100            0.941064   \n",
            "75%        6.296602      1.691958     23.330300            1.034005   \n",
            "max        7.136170     12.110300     34.783400            1.631470   \n",
            "\n",
            "        HydWtr_Na2O  \n",
            "count  51276.000000  \n",
            "mean       0.809311  \n",
            "std        0.696798  \n",
            "min        0.000000  \n",
            "25%        0.453939  \n",
            "50%        0.665013  \n",
            "75%        0.983819  \n",
            "max       12.882300  \n",
            "            Butanol\n",
            "count  51276.000000\n",
            "mean       9.823222\n",
            "std       10.224860\n",
            "min        0.000000\n",
            "25%        3.833330\n",
            "50%        5.900000\n",
            "75%       10.929050\n",
            "max       58.786900\n"
          ]
        }
      ],
      "source": [
        "print(df_CDunit.describe())\n",
        "print(df_AlCon.describe())\n",
        "print(df_FB554.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data type for 'Date' column in df_CDunit: object\n",
            "Data type for 'Date' column in df_FB554: object\n",
            "Data type for 'Date' column in df_AlCon: object\n"
          ]
        }
      ],
      "source": [
        "print(\"Data type for 'Date' column in df_CDunit:\", df_CDunit['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_FB554:\", df_FB554['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_AlCon:\", df_AlCon['Date'].dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_CDunit['Date'] = pd.to_datetime(df_CDunit['Date'], errors='coerce')\n",
        "df_FB554['Date'] = pd.to_datetime(df_FB554['Date'], errors='coerce')\n",
        "df_AlCon['Date'] = pd.to_datetime(df_AlCon['Date'], errors='coerce')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data type for 'Date' column in df_CDunit: datetime64[ns]\n",
            "Data type for 'Date' column in df_FB554: datetime64[ns]\n",
            "Data type for 'Date' column in df_AlCon: datetime64[ns]\n"
          ]
        }
      ],
      "source": [
        "print(\"Data type for 'Date' column in df_CDunit:\", df_CDunit['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_FB554:\", df_FB554['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_AlCon:\", df_AlCon['Date'].dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Date', 'DI55102', 'DI55152', 'FC55003', 'FC55552', 'FC55569',\n",
            "       'FC55576', 'FFC55555', 'LC55557', 'LC90366', 'LC90368', 'TC55552'],\n",
            "      dtype='object')\n",
            "Index(['Date', 'Butanol'], dtype='object')\n",
            "Index(['Date', '425_pct_Al', 'C4_pct_Eth', 'C4_pct_H2O', 'HydWtr_pct_Ammonia',\n",
            "       'HydWtr_Na2O'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df_CDunit.columns)\n",
        "print(df_FB554.columns)\n",
        "print(df_AlCon.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_rolling_average_to_df(df, rolling_size):\n",
        "    # Ensure 'Date' is the index if it's not already\n",
        "    if df.index.name != 'Date':\n",
        "        df = df.set_index('Date')\n",
        "\n",
        "    # Apply rolling average to all columns\n",
        "    rolled_df = df.rolling(window=rolling_size, min_periods=1).mean()\n",
        "\n",
        "    # Reset index to make 'Date' a column again\n",
        "    rolled_df = rolled_df.reset_index()\n",
        "\n",
        "    return rolled_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_time_shift_by_hours(df, shift_hours):\n",
        "    \"\"\"\n",
        "    Shifts the DataFrame's datetime index by the specified number of hours.\n",
        "\n",
        "    :param df: DataFrame with 'Date' as its datetime index or column.\n",
        "    :param shift_hours: Number of hours to shift. Can be positive (forward) or negative (backward).\n",
        "    :return: Shifted DataFrame.\n",
        "    \"\"\"\n",
        "    # Convert 'Date' to datetime and set as index if it's not already\n",
        "    if df.index.name != 'Date':\n",
        "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "        df = df.set_index('Date')\n",
        "\n",
        "    # Ensure the index is a DatetimeIndex\n",
        "    df.index = pd.to_datetime(df.index)\n",
        "\n",
        "    # Shift the DataFrame's index by the specified number of hours\n",
        "    df.index = df.index + pd.Timedelta(hours=shift_hours)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Usage Examples\n",
        "# shift_hours_AlCon = 1  # Negative shift for df_AlCon (e.g., -5 hours backward)\n",
        "# shift_hours_FB554 = 5   # Positive shift for df_FB554 (e.g., 5 hours forward)\n",
        "\n",
        "# shifted_df_AlCon = apply_time_shift_by_hours(df_AlCon, shift_hours_AlCon)\n",
        "# print(\"Shifted df_AlCon:\")\n",
        "# print(shifted_df_AlCon.head())\n",
        "\n",
        "# shifted_df_FB554 = apply_time_shift_by_hours(df_FB554, shift_hours_FB554)\n",
        "# print(\"\\nShifted df_FB554:\")\n",
        "# print(shifted_df_FB554.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def join_df_FB554_to_df_CDunit(df_CDunit, df_FB554):\n",
        "    # Reset index if 'Date' is the index\n",
        "    if df_CDunit.index.name == 'Date':\n",
        "        df_CDunit = df_CDunit.reset_index()\n",
        "    if df_FB554.index.name == 'Date':\n",
        "        df_FB554 = df_FB554.reset_index()\n",
        "\n",
        "    # Ensure 'Date' columns are datetime objects and sort DataFrames\n",
        "    df_CDunit['Date'] = pd.to_datetime(df_CDunit['Date'], errors='coerce')\n",
        "    df_FB554['Date'] = pd.to_datetime(df_FB554['Date'], errors='coerce')\n",
        "\n",
        "    df_CDunit = df_CDunit.dropna(subset=['Date']).sort_values('Date')\n",
        "    df_FB554 = df_FB554.dropna(subset=['Date']).sort_values('Date')\n",
        "\n",
        "    # Perform merge_asof\n",
        "    combined_df = pd.merge_asof(df_FB554, df_CDunit, on='Date', direction='nearest')\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "def join_df_AlCon_to_combined_df(combined_df, df_AlCon):\n",
        "    # Reset index if 'Date' is the index\n",
        "    if combined_df.index.name == 'Date':\n",
        "        combined_df = combined_df.reset_index()\n",
        "    if df_AlCon.index.name == 'Date':\n",
        "        df_AlCon = df_AlCon.reset_index()\n",
        "\n",
        "    # Ensure 'Date' columns are datetime objects and sort DataFrames\n",
        "    combined_df['Date'] = pd.to_datetime(combined_df['Date'], errors='coerce')\n",
        "    df_AlCon['Date'] = pd.to_datetime(df_AlCon['Date'], errors='coerce')\n",
        "\n",
        "    combined_df = combined_df.dropna(subset=['Date']).sort_values('Date')\n",
        "    df_AlCon = df_AlCon.dropna(subset=['Date']).sort_values('Date')\n",
        "\n",
        "    # Perform merge_asof\n",
        "    combined_df_all = pd.merge_asof(df_AlCon, combined_df, on='Date', direction='nearest')\n",
        "    \n",
        "    return combined_df_all\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data type for 'Date' column in df_CDunit: datetime64[ns]\n",
            "Data type for 'Date' column in df_FB554: datetime64[ns]\n",
            "Data type for 'Date' column in df_AlCon: datetime64[ns]\n"
          ]
        }
      ],
      "source": [
        "print(\"Data type for 'Date' column in df_CDunit:\", df_CDunit['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_FB554:\", df_FB554['Date'].dtypes)\n",
        "print(\"Data type for 'Date' column in df_AlCon:\", df_AlCon['Date'].dtypes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_data_limited():\n",
        "    # Apply the specific rolling average directly\n",
        "    rolled_df_CDunit = apply_rolling_average_to_df(df_CDunit, 8)\n",
        "    rolled_df_FB554 = apply_rolling_average_to_df(df_FB554, 4)\n",
        "    rolled_df_AlCon = apply_rolling_average_to_df(df_AlCon, 2)\n",
        "\n",
        "    # Apply the specific time shifts directly\n",
        "    rolled_df_AlCon_shifted = apply_time_shift_by_hours(rolled_df_AlCon, -1) # Assuming apply_time_shift_by_hours handles negative shifts correctly\n",
        "    rolled_df_FB554_shifted = apply_time_shift_by_hours(rolled_df_FB554, 1)\n",
        "\n",
        "    # Combine df_CDunit and df_FB554 to create combined_df\n",
        "    combined_df = join_df_FB554_to_df_CDunit(rolled_df_CDunit, rolled_df_FB554_shifted)\n",
        "\n",
        "    # Combine combined_df with rolled_df_AlCon to create combined_df_all\n",
        "    combined_df_all = join_df_AlCon_to_combined_df(combined_df, rolled_df_AlCon_shifted)\n",
        "\n",
        "    # At this point, combined_df_all is the DataFrame with the data processed by the specified shifts and averages\n",
        "    return combined_df_all\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 Date  425_pct_Al  C4_pct_Eth  C4_pct_H2O  HydWtr_pct_Ammonia  \\\n",
            "0 2012-05-16 15:00:00    6.306930    2.505710    21.95810            0.909887   \n",
            "1 2012-05-16 16:00:00    6.307280    2.507065    21.96075            0.909326   \n",
            "2 2012-05-16 18:00:00    6.308335    2.511135    21.96865            0.907643   \n",
            "3 2012-05-16 19:00:00    6.309390    2.515210    21.97655            0.905959   \n",
            "4 2012-05-16 20:00:00    6.310090    2.517925    21.98185            0.904837   \n",
            "\n",
            "   HydWtr_Na2O    Butanol   DI55102   DI55152    FC55003   FC55552   FC55569  \\\n",
            "0     2.618940  58.526500  0.970151  0.924718  4968.4400  41476.45  6915.395   \n",
            "1     2.665560  58.526500  0.970151  0.924718  4968.4400  41476.45  6915.395   \n",
            "2     2.805415  56.692400  0.970151  0.924718  4968.4400  41476.45  6915.395   \n",
            "3     2.945270  56.692400  0.970151  0.924718  4968.4400  41476.45  6915.395   \n",
            "4     3.038505  53.635533  0.970441  0.923875  5205.8625  41490.25  6915.535   \n",
            "\n",
            "     FC55576  FFC55555    LC55557    LC90366   LC90368    TC55552  \n",
            "0  338.08450  0.751216  65.844650  62.291900  51.34935  177.18800  \n",
            "1  338.08450  0.751216  65.844650  62.291900  51.34935  177.18800  \n",
            "2  338.08450  0.751216  65.844650  62.291900  51.34935  177.18800  \n",
            "3  338.08450  0.751216  65.844650  62.291900  51.34935  177.18800  \n",
            "4  334.65925  0.750611  65.922175  58.413975  51.01720  177.35975  \n"
          ]
        }
      ],
      "source": [
        "# Make sure all your helper functions and initial DataFrames (df_CDunit, df_FB554, df_AlCon) are correctly defined\n",
        "\n",
        "# Now, call the modified process_data function to get the processed DataFrame\n",
        "final_dataset = process_data_limited()\n",
        "\n",
        "# Inspect the final_dataset\n",
        "print(final_dataset.head())  # Print the first few rows to inspect the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save DataFrame to CSV file in the same directory as the Jupyter Notebook\n",
        "# model_results.to_csv('merged_data'.csv', index=False)\n",
        "                     \n",
        "# Save DataFrame to CSV file in the same directory as the Jupyter Notebook\n",
        "# df_CD.to_csv(r'C:\\Users\\steve\\OneDrive\\1. BAIUTEK\\Project-OptiC4\\1 Preprocess\\Continuous Data\\contData_all.csv', index=False)            \n",
        "\n",
        "final_dataset.to_csv(r'C:\\Users\\austinsh\\Project-OptiC4\\III Models\\3 Model C4\\5 Preprocessing - Slecected Features\\Merge Data\\merged_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-21 22:36:18.245737\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Get the current date and time\n",
        "current_date_time = datetime.now()\n",
        "\n",
        "# Print the current date and time\n",
        "print(current_date_time)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
